{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54139b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:37:55.914561Z",
     "iopub.status.busy": "2025-11-26T09:37:55.913934Z",
     "iopub.status.idle": "2025-11-26T09:38:01.763552Z",
     "shell.execute_reply": "2025-11-26T09:38:01.762476Z"
    },
    "papermill": {
     "duration": 5.854803,
     "end_time": "2025-11-26T09:38:01.765354",
     "exception": false,
     "start_time": "2025-11-26T09:37:55.910551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e0072d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:38:01.770726Z",
     "iopub.status.busy": "2025-11-26T09:38:01.770421Z",
     "iopub.status.idle": "2025-11-26T09:38:06.798281Z",
     "shell.execute_reply": "2025-11-26T09:38:06.797178Z"
    },
    "papermill": {
     "duration": 5.032089,
     "end_time": "2025-11-26T09:38:06.799632",
     "exception": false,
     "start_time": "2025-11-26T09:38:01.767543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables set.\n",
      "‚úÖ Kaggle API Authenticated.\n",
      "‚úÖ Gemini API Authenticated.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & AUTHENTICATION (CORRECT ORDER) ---\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 1. Retrieve Secrets & Set Env Vars FIRST\n",
    "# (We do this BEFORE importing the kaggle library to prevent the crash)\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    # Get secrets\n",
    "    gemini_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "    k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "\n",
    "    # Set Environment Variables\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "    os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "    print(\"‚úÖ Environment variables set.\")\n",
    "    \n",
    "    # 2. NOW it is safe to import the Kaggle API\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    k_api = KaggleApi()\n",
    "    k_api.authenticate()\n",
    "    print(\"‚úÖ Kaggle API Authenticated.\")\n",
    "\n",
    "    # 3. Authenticate Gemini\n",
    "    genai.configure(api_key=gemini_key)\n",
    "    print(\"‚úÖ Gemini API Authenticated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a1cf41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:38:06.804843Z",
     "iopub.status.busy": "2025-11-26T09:38:06.804429Z",
     "iopub.status.idle": "2025-11-26T09:41:19.665818Z",
     "shell.execute_reply": "2025-11-26T09:41:19.664970Z"
    },
    "papermill": {
     "duration": 192.867403,
     "end_time": "2025-11-26T09:41:19.668880",
     "exception": false,
     "start_time": "2025-11-26T09:38:06.801477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING KAGGLE COMMAND FOR: rsna-intracranial-aneurysm-detection\n",
      "==================================================\n",
      "üïµÔ∏è [Scout] Analyzing competition: rsna-intracranial-aneurysm-detection...\n",
      "üì° [Forum] Scanning discussions for: rsna-intracranial-aneurysm-detection...\n",
      "üë®‚Äçüíª [Notebook] Hunting for top code...\n",
      "   (Found: RSNA Aneurysm Detection Demo Submission)\n",
      "üß† [Strategist] Formulating plan...\n",
      "üèóÔ∏è [Builder] Writing final solution.py...\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìÑ STRATEGY REPORT\n",
       "As a Kaggle Grandmaster, let's dissect the RSNA Intracranial Aneurysm Detection challenge and formulate a winning strategy. This competition demands not just accuracy but also robust, efficient inference on 3D CT data.\n",
       "\n",
       "---\n",
       "\n",
       "## Winning Strategy: RSNA Intracranial Aneurysm Detection\n",
       "\n",
       "**Competition Overview:**\n",
       "The goal is to detect and classify intracranial aneurysms across various anatomical locations on 3D CT scans, ultimately predicting the presence and location of aneurysms with a Weighted Log Loss metric. The data consists of substantial 85GB 3D DICOM files, and inference is online with a 30-minute time limit per series.\n",
       "\n",
       "### 1. Critique of the Existing Code Baseline\n",
       "\n",
       "The provided baseline is **minimalistic and purely serves as an API scaffold**, not a predictive solution.\n",
       "*   **No Predictive Logic:** It contains no actual model loading, DICOM processing, or inference code. It merely demonstrates the function signature (`predict(series_path) -> pl.DataFrame | pd.DataFrame`) and the expected output format (a DataFrame with `LABEL_COLS`).\n",
       "*   **Online Inference Constraint Highlighted:** The explicit mention of the \"30 minutes per series\" constraint is the most valuable piece of information from the baseline. This immediately signals that model efficiency and streamlined data processing will be paramount for a successful submission. Ensembles of very large models might be challenging to deploy effectively under this time limit.\n",
       "*   **DICOM Handling Implied:** The `DICOM_TAG_ALLOWLIST` indicates that core image data and relevant metadata will be present, but potentially stripped of sensitive or less common tags. The baseline, however, doesn't demonstrate how to load and convert the series of 2D DICOM slices into a coherent 3D volume.\n",
       "\n",
       "**In essence, the baseline is a blank canvas. Our strategy must build a complete solution from the ground up, keeping the online inference constraints firmly in mind.**\n",
       "\n",
       "### 2. Specific Model Architecture\n",
       "\n",
       "Given the 3D nature of the data and the multi-label classification task, a powerful 3D Convolutional Neural Network (CNN) is essential.\n",
       "\n",
       "**Recommended Architecture: A 3D ResNeXt/EfficientNet-like Backbone with Multi-Head Classification**\n",
       "\n",
       "1.  **3D Backbone:** We will leverage a robust 3D CNN architecture for feature extraction.\n",
       "    *   **Choice:** A 3D adaptation of architectures like **ResNeXt** or **EfficientNet** provides strong capabilities in medical imaging. ResNeXt, with its \"cardinality\" concept, offers a good balance between accuracy and computational efficiency by aggregating parallel branches. An EfficientNet-like approach scales the model width, depth, and resolution in a principled way.\n",
       "    *   **Implementation:** The backbone will take the preprocessed 3D CT volume as input. Each convolutional layer will be a 3D convolution (e.g., `Conv3D` in TensorFlow/PyTorch).\n",
       "    *   **Reasoning:** These architectures are proven to extract hierarchical, context-rich features from images, which is crucial for detecting subtle aneurysms amidst complex brain anatomy. Using 3D convolutions allows the model to learn spatial relationships across slices, essential for aneurysm detection.\n",
       "\n",
       "2.  **Global Pooling:** After the final convolutional block of the backbone, apply a Global Average Pooling (GAP) layer.\n",
       "    *   **Reasoning:** GAP effectively summarizes the learned features across the entire 3D volume into a fixed-size vector, making the model robust to variations in input dimensions and reducing the number of parameters in the subsequent classification layers.\n",
       "\n",
       "3.  **Multi-Head Classification:** Attach multiple independent fully connected (Dense) layers, each with a sigmoid activation, directly after the GAP layer.\n",
       "    *   **Structure:** Each head will correspond to one of the `LABEL_COLS` (e.g., one head for 'Left Infraclinoid Internal Carotid Artery', another for 'Right Middle Cerebral Artery', etc., and crucially, one for 'Aneurysm Present').\n",
       "    *   **Reasoning:** This multi-head approach allows the model to learn common underlying features for aneurysm detection, while each head specializes in predicting the presence in a specific anatomical location. The 'Aneurysm Present' head acts as an overall binary classifier, which is a strong signal for the Weighted Log Loss.\n",
       "\n",
       "4.  **Loss Function:** Weighted Binary Cross-Entropy (BCE) loss.\n",
       "    *   **Reasoning:** Given the class imbalance (aneurysms are rare, and some locations are rarer than others), applying inverse class frequency weighting to the BCE loss for each head will ensure the model pays adequate attention to the minority positive class.\n",
       "\n",
       "**Considerations for online inference:**\n",
       "*   Start with a moderately sized model (e.g., 3D ResNeXt-50 equivalent). Monitor inference time during development.\n",
       "*   Pre-load the model into memory once at the start of the `kaggle_evaluation.rsna_inference_server` process to avoid repeated loading overhead.\n",
       "\n",
       "### 3. Specific Data Augmentation or Feature Engineering Technique\n",
       "\n",
       "**Technique: Multi-Window CT Input Channels**\n",
       "\n",
       "**Description:** Instead of feeding a single windowed CT volume (e.g., brain window) into the model, we will preprocess the raw Hounsfield Unit (HU) values into *multiple, distinct CT windows* and provide these as separate input channels to the 3D CNN.\n",
       "\n",
       "**Example Windows:**\n",
       "1.  **Brain Parenchyma Window:** Typically centered around 40 HU with a width of 80 HU (e.g., levels between 0-80 HU). This highlights grey and white matter.\n",
       "2.  **Bone Window:** Centered around 400-800 HU with a width of 1500-2000 HU (e.g., levels between -500 to 1500 HU). Useful for identifying skull base structures and potential calcifications related to aneurysms.\n",
       "3.  **Angiographic/Vessel Window:** A narrower window specifically tuned to highlight vascular structures, often in the range of 80-150 HU.\n",
       "4.  **Raw Normalized HU:** The original, normalized HU values (e.g., scaled to 0-1 or -1 to 1) for a broader context.\n",
       "\n",
       "**How it works:**\n",
       "Each 3D CT scan will be transformed into a 3D tensor with, for example, 3 or 4 channels instead of 1. The model's initial 3D convolutional layer will then operate on these multi-channel inputs.\n",
       "\n",
       "**Benefits:**\n",
       "*   **Mimics Radiologist Practice:** Radiologists routinely adjust window levels to optimally visualize different tissues and pathologies. This technique allows the model to simultaneously \"see\" the image through multiple radiological perspectives.\n",
       "*   **Rich Feature Representation:** Different windows emphasize different anatomical details. Combining them provides the CNN with a much richer and more robust representation of the local environment around potential aneurysms (e.g., vessel wall, surrounding brain tissue, bony landmarks).\n",
       "*   **Improved Small Object Detection:** Aneurysms can be small. Providing focused contrast for vessels and surrounding structures helps the model pick up subtle cues that might be lost in a single general window.\n",
       "*   **No Additional Model Complexity:** This is a preprocessing step that simply changes the input tensor shape (e.g., `(D, H, W, 1)` to `(D, H, W, 4)`), requiring no fundamental change to the CNN architecture itself beyond handling more input channels in the first layer.\n",
       "\n",
       "**Augmentation (briefly):**\n",
       "In addition to this feature engineering, standard 3D augmentations like random rotations, flips (left-right), slight scaling, intensity shifts, and elastic deformations should be applied during training to improve generalization.\n",
       "\n",
       "### 4. Validation Strategy\n",
       "\n",
       "A robust validation strategy is paramount to ensure our model generalizes well to unseen data and correctly estimates its performance on the Weighted Log Loss metric.\n",
       "\n",
       "**Strategy: Grouped K-Fold Cross-Validation with Stratification**\n",
       "\n",
       "1.  **Patient-Level Splitting (Grouping):**\n",
       "    *   **Core Principle:** The most critical rule in medical imaging competitions is to ensure that data from the same patient (or study, if a patient can have multiple unique studies) does not appear in both the training and validation sets. This prevents data leakage and over-optimistic performance estimates.\n",
       "    *   **Implementation:** Use `GroupKFold` from `sklearn.model_selection`. The `groups` argument should be based on `StudyInstanceUID` or `PatientID` (prioritize `StudyInstanceUID` if available and unique per scan, as one patient might have multiple studies over time).\n",
       "    *   **Number of Folds:** 5-folds is a good balance between training time and robust validation estimates.\n",
       "\n",
       "2.  **Stratification:**\n",
       "    *   **Challenge:** Aneurysm presence, and especially specific anatomical locations, will likely be highly imbalanced classes.\n",
       "    *   **Implementation:** Stratify the splits based on the 'Aneurysm Present' label. If possible, a multi-label stratification strategy (considering all `LABEL_COLS` or at least the 'Aneurysm Present' and a few most common specific locations) would be ideal to ensure each fold has a representative distribution of positive and negative cases across various aneurysm types. This might require custom stratification logic if `GroupKFold` alone isn't sufficient for multi-label stratification.\n",
       "    *   **Reasoning:** Stratification ensures that each fold's validation set is representative of the overall label distribution, leading to more reliable performance metrics.\n",
       "\n",
       "3.  **Metric Calculation:**\n",
       "    *   **During Validation:** The primary metric for validation will be the **Weighted Log Loss**, as defined by the competition. Implement the exact calculation logic to ensure consistency.\n",
       "    *   **Secondary Metrics:** Monitor other metrics like AUC (Area Under the Receiver Operating Characteristic curve) or Average Precision (AP) for individual labels, especially for the rare classes, as these can provide insights not fully captured by Log Loss.\n",
       "\n",
       "4.  **Training Procedure:**\n",
       "    *   Train a separate instance of the model (with the architecture described above) on each fold of the K-Fold split.\n",
       "    *   Save the best performing model checkpoint for each fold (based on validation Weighted Log Loss).\n",
       "\n",
       "5.  **Inference (for Submission):**\n",
       "    *   **Ensembling:** The most common Grandmaster strategy is to ensemble the predictions from the models trained on each fold. Average the predicted probabilities from each of the N models (e.g., 5-fold models). This reduces variance and typically improves robustness.\n",
       "    *   **Test-Time Augmentation (TTA):** For each test series, perform inference on multiple augmented versions (e.g., original, flipped left-right, rotated slightly) and average their predictions. This further boosts robustness but adds to inference time. Carefully balance the number of TTA transformations with the 30-minute time limit.\n",
       "\n",
       "**Example Validation Loop:**\n",
       "\n",
       "```python\n",
       "from sklearn.model_selection import GroupKFold\n",
       "import numpy as np\n",
       "import pandas as pd # or polars\n",
       "\n",
       "# Assuming 'train_df' contains 'StudyInstanceUID' and all LABEL_COLS\n",
       "groups = train_df['StudyInstanceUID'].values\n",
       "labels = train_df[LABEL_COLS].values # For stratification if possible\n",
       "\n",
       "kf = GroupKFold(n_splits=5)\n",
       "\n",
       "for fold, (train_idx, val_idx) in enumerate(kf.split(train_df, groups=groups)):\n",
       "    print(f\"--- Fold {fold+1}/{kf.n_splits} ---\")\n",
       "    \n",
       "    fold_train_data = train_df.iloc[train_idx]\n",
       "    fold_val_data = train_df.iloc[val_idx]\n",
       "    \n",
       "    # Check for patient leakage:\n",
       "    assert len(set(fold_train_data['StudyInstanceUID']) & set(fold_val_data['StudyInstanceUID'])) == 0\n",
       "    \n",
       "    # 1. Preprocess and load 3D volumes for fold_train_data and fold_val_data\n",
       "    # 2. Train model on fold_train_data, evaluating on fold_val_data\n",
       "    #    - Apply Multi-Window CT Input Channels preprocessing\n",
       "    #    - Apply 3D augmentations during training\n",
       "    #    - Use Weighted Binary Cross-Entropy loss\n",
       "    #    - Monitor Weighted Log Loss on validation set\n",
       "    # 3. Save best model for this fold\n",
       "    # 4. Store validation predictions and true labels for overall evaluation\n",
       "```\n",
       "\n",
       "This strategy focuses on leveraging advanced 3D CNNs, enriching the input data with expert knowledge (multi-windowing), and validating performance rigorously through patient-level grouped cross-validation, while always keeping the tight online inference constraints in mind."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üêç GENERATED CODE\n",
       "Error: Generation failed with 400 Bad Request"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code saved to 'submission.py'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. IMPORTS & SETUP ---\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from ddgs import DDGS\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# --- 2. AUTHENTICATION & CONFIG ---\n",
    "def setup_system():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        # Gemini Auth\n",
    "        api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        # Kaggle Auth\n",
    "        k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "        k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "        \n",
    "        # Set Env Vars (Safest method)\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "        os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "        \n",
    "        # Initialize API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Auth Error: {e}\")\n",
    "        return None\n",
    "\n",
    "k_api = setup_system()\n",
    "\n",
    "# UPDATED: Use the stable 1.5 Flash model\n",
    "model_name = 'gemini-2.5-flash' \n",
    "\n",
    "# Safety Config (Block None to allow medical/technical discussions)\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "# --- HELPER: SAFE GENERATION ---\n",
    "# --- HELPER: ROBUST STREAMING GENERATION ---\n",
    "def safe_generate(model, prompt):\n",
    "    \"\"\"\n",
    "    Uses streaming to bypass 503 Upstream Timeouts on long code generation.\n",
    "    Does NOT rely on 'timeout' parameter, but on active connection keep-alive.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Enable streaming. This creates a generator that yields text chunks.\n",
    "        response_iterator = model.generate_content(prompt, safety_settings=safety_config, stream=True)\n",
    "        \n",
    "        full_text = \"\"\n",
    "        # Iterate through the chunks as they arrive.\n",
    "        # This loop keeps the HTTP connection active, preventing timeouts.\n",
    "        for chunk in response_iterator:\n",
    "            if chunk.text:\n",
    "                full_text += chunk.text\n",
    "        \n",
    "        if not full_text:\n",
    "            return \"Error: Model returned empty response.\"\n",
    "            \n",
    "        return full_text\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: Generation failed with {str(e)}\"\n",
    "\n",
    "# --- 3. AGENT DEFINITIONS ---\n",
    "\n",
    "class ProblemScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üïµÔ∏è [Scout] Analyzing competition: {slug}...\")\n",
    "        try:\n",
    "            # RSNA Override\n",
    "            if \"rsna\" in slug and \"aneurysm\" in slug:\n",
    "                return \"Goal: Detect intracranial aneurysms on 3D CT. Metric: Weighted Log Loss. Data: 85GB 3D DICOM.\"\n",
    "            \n",
    "            # API Fetch\n",
    "            comps = k_api.competitions_list(search=slug.split('-')[0])\n",
    "            target = next((c for c in comps if c.ref == slug), None)\n",
    "            if target:\n",
    "                return f\"Goal: {target.description[:500]}... Metric: {target.evaluationMetric}.\"\n",
    "            return \"Could not fetch official details via API.\"\n",
    "        except Exception as e:\n",
    "            return f\"Scout Error: {e}\"\n",
    "\n",
    "class ForumScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üì° [Forum] Scanning discussions for: {slug}...\")\n",
    "        readable_name = slug.replace(\"-\", \" \")\n",
    "        query = f\"{readable_name} kaggle discussion solution tricks\"\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=5))\n",
    "            \n",
    "            if not results: return \"No discussions found.\"\n",
    "            summary = \"\\n\".join([f\"- {r['title']}: {r['body'][:200]}...\" for r in results])\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Forum Search Error: {e}\"\n",
    "\n",
    "class NotebookScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üë®‚Äçüíª [Notebook] Hunting for top code...\")\n",
    "        try:\n",
    "            kernels = []\n",
    "            try: kernels = k_api.kernels_list(competition=slug, sort_by='voteCount', page_size=1)\n",
    "            except: pass\n",
    "            \n",
    "            if not kernels:\n",
    "                print(\"   (Strict filter failed, trying broad search...)\")\n",
    "                kernels = k_api.kernels_list(search=slug.split('-')[0], sort_by='voteCount', page_size=1)\n",
    "            \n",
    "            if not kernels: return \"No public code found.\"\n",
    "            \n",
    "            top_k = kernels[0]\n",
    "            print(f\"   (Found: {top_k.title})\")\n",
    "            \n",
    "            k_api.kernels_pull(top_k.ref, path=\"./downloaded_code\")\n",
    "            \n",
    "            code_content = \"\"\n",
    "            files = glob.glob(\"./downloaded_code/*\")\n",
    "            for f_path in files:\n",
    "                if f_path.endswith(\".py\"):\n",
    "                    with open(f_path,'r') as f: code_content += f.read()\n",
    "                elif f_path.endswith(\".ipynb\"):\n",
    "                    with open(f_path,'r') as f:\n",
    "                        nb = json.load(f)\n",
    "                        for c in nb['cells']: \n",
    "                            if c['cell_type']=='code': code_content += \"\".join(c['source']) + \"\\n\"\n",
    "            \n",
    "            if len(code_content) < 50: return \"Code was empty.\"\n",
    "            return f\"--- CODE FROM {top_k.title} ---\\n{code_content[:25000]}\"\n",
    "        except Exception as e:\n",
    "            return f\"Code Download Error: {e}\"\n",
    "\n",
    "class StrategistAgent:\n",
    "    def run(self, slug, goal, forum_intel, code_intel):\n",
    "        print(f\"üß† [Strategist] Formulating plan...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Act as a Kaggle Grandmaster.\n",
    "        Competition: {slug}\n",
    "        \n",
    "        1. OFFICIAL GOAL: {goal}\n",
    "        2. COMMUNITY INTEL: {forum_intel}\n",
    "        3. EXISTING CODE BASELINE: {code_intel[:2000]}... (truncated)\n",
    "        \n",
    "        Task: Write a 'Winning Strategy' report.\n",
    "        - Critique the baseline.\n",
    "        - Identify the specific model architecture we should build.\n",
    "        - Suggest 1 specific data augmentation or feature engineering technique.\n",
    "        - Define the validation strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "class CodeGeneratorAgent:\n",
    "    def run(self, strategy_report):\n",
    "        print(f\"üèóÔ∏è [Builder] Writing final solution.py...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python Developer.\n",
    "        \n",
    "        Based on this strategy:\n",
    "        {strategy_report}\n",
    "        \n",
    "        Write a COMPLETE, RUNNABLE 'main.py' script.\n",
    "        - Include Dataset class, Model class, and Training Loop.\n",
    "        - Use PyTorch.\n",
    "        - Handle the specific data types mentioned (e.g. Images, CSVs).\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "# --- 4. THE ORCHESTRATOR ---\n",
    "\n",
    "class KaggleCommandSystem:\n",
    "    def __init__(self):\n",
    "        self.scout = ProblemScoutAgent()\n",
    "        self.forum = ForumScoutAgent()\n",
    "        self.notebook = NotebookScoutAgent()\n",
    "        self.strategist = StrategistAgent()\n",
    "        self.builder = CodeGeneratorAgent()\n",
    "        \n",
    "    def execute(self, competition_slug):\n",
    "        print(f\"üöÄ STARTING KAGGLE COMMAND FOR: {competition_slug}\\n\" + \"=\"*50)\n",
    "        \n",
    "        goal_data = self.scout.run(competition_slug)\n",
    "        forum_data = self.forum.run(competition_slug)\n",
    "        code_data = self.notebook.run(competition_slug)\n",
    "        \n",
    "        strategy = self.strategist.run(competition_slug, goal_data, forum_data, code_data)\n",
    "        \n",
    "        # If strategy failed, don't try to build code\n",
    "        if \"Error\" in strategy and len(strategy) < 100:\n",
    "            return {\"strategy_report\": strategy, \"final_code\": \"Skipped due to strategy error.\"}\n",
    "            \n",
    "        final_code = self.builder.run(strategy)\n",
    "        \n",
    "        return {\n",
    "            \"strategy_report\": strategy,\n",
    "            \"final_code\": final_code\n",
    "        }\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "system = KaggleCommandSystem()\n",
    "slug = \"rsna-intracranial-aneurysm-detection\" \n",
    "# You can change 'slug' to 'hull-tactical-speed-dating' or any other active comp to test\n",
    "\n",
    "try:\n",
    "    result = system.execute(slug)\n",
    "    \n",
    "    from IPython.display import Markdown, display\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üìÑ STRATEGY REPORT\\n{result['strategy_report']}\"))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üêç GENERATED CODE\\n{result['final_code']}\"))\n",
    "    \n",
    "    with open(\"submission.py\", \"w\") as f:\n",
    "        f.write(result['final_code'])\n",
    "    print(\"‚úÖ Code saved to 'submission.py'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fatal System Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 211.27581,
   "end_time": "2025-11-26T09:41:22.554995",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T09:37:51.279185",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
