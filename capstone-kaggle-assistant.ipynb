{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511881aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:15:02.048735Z",
     "iopub.status.busy": "2025-11-25T17:15:02.048366Z",
     "iopub.status.idle": "2025-11-25T17:15:08.744000Z",
     "shell.execute_reply": "2025-11-25T17:15:08.742627Z"
    },
    "papermill": {
     "duration": 6.701689,
     "end_time": "2025-11-25T17:15:08.746209",
     "exception": false,
     "start_time": "2025-11-25T17:15:02.044520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39739f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:15:08.753209Z",
     "iopub.status.busy": "2025-11-25T17:15:08.752182Z",
     "iopub.status.idle": "2025-11-25T17:15:14.788789Z",
     "shell.execute_reply": "2025-11-25T17:15:14.787650Z"
    },
    "papermill": {
     "duration": 6.041858,
     "end_time": "2025-11-25T17:15:14.790541",
     "exception": false,
     "start_time": "2025-11-25T17:15:08.748683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables set.\n",
      "‚úÖ Kaggle API Authenticated.\n",
      "‚úÖ Gemini API Authenticated.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & AUTHENTICATION (CORRECT ORDER) ---\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 1. Retrieve Secrets & Set Env Vars FIRST\n",
    "# (We do this BEFORE importing the kaggle library to prevent the crash)\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    # Get secrets\n",
    "    gemini_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "    k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "\n",
    "    # Set Environment Variables\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "    os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "    print(\"‚úÖ Environment variables set.\")\n",
    "    \n",
    "    # 2. NOW it is safe to import the Kaggle API\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    k_api = KaggleApi()\n",
    "    k_api.authenticate()\n",
    "    print(\"‚úÖ Kaggle API Authenticated.\")\n",
    "\n",
    "    # 3. Authenticate Gemini\n",
    "    genai.configure(api_key=gemini_key)\n",
    "    print(\"‚úÖ Gemini API Authenticated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57e3711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:15:14.797741Z",
     "iopub.status.busy": "2025-11-25T17:15:14.797212Z",
     "iopub.status.idle": "2025-11-25T17:25:39.657973Z",
     "shell.execute_reply": "2025-11-25T17:25:39.656613Z"
    },
    "papermill": {
     "duration": 624.867642,
     "end_time": "2025-11-25T17:25:39.660466",
     "exception": false,
     "start_time": "2025-11-25T17:15:14.792824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING KAGGLE COMMAND FOR: rsna-intracranial-aneurysm-detection\n",
      "==================================================\n",
      "üïµÔ∏è [Scout] Analyzing competition: rsna-intracranial-aneurysm-detection...\n",
      "üì° [Forum] Scanning discussions for: rsna-intracranial-aneurysm-detection...\n",
      "üë®‚Äçüíª [Notebook] Hunting for top code...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/845812907.py:95: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   (Found: RSNA Aneurysm Detection Demo Submission)\n",
      "üß† [Strategist] Formulating plan...\n",
      "üèóÔ∏è [Builder] Writing final solution.py...\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìÑ STRATEGY REPORT\n",
       "As a Kaggle Grandmaster, let's dissect the `rsna-intracranial-aneurysm-detection` challenge and formulate a winning strategy. This competition demands robust 3D image processing and classification, focusing on a critical medical task with high stakes.\n",
       "\n",
       "---\n",
       "\n",
       "### Winning Strategy Report: RSNA Intracranial Aneurysm Detection\n",
       "\n",
       "#### 1. Critique of the Baseline\n",
       "\n",
       "The provided baseline code is not a machine learning solution; rather, it's a **submission scaffolding**. Its primary function is to demonstrate how to read DICOM files and structure a submission for the inference server.\n",
       "\n",
       "**Specific Critiques:**\n",
       "\n",
       "*   **No Model Inference:** The `predict` function is truncated and explicitly states \"Replace this section with your own prediction code.\" This means it lacks any actual aneurysm detection logic, image processing, or a trained model.\n",
       "*   **Minimal Data Handling:** While it uses `pydicom` to read DICOMs and hints at `polars` for efficient DataFrame operations, it performs no critical medical image preprocessing steps such as Hounsfield Unit (HU) windowing, intensity normalization, or 3D volume reconstruction.\n",
       "*   **Placeholder for a Challenge:** It serves its purpose as a functional, albeit empty, submission template. For a competition of this nature, a true baseline would typically involve at least a simple 2D CNN on slices, or a rudimentary 3D CNN, to establish a performance benchmark.\n",
       "*   **Inefficient for 3D:** Merely iterating through files in a directory will be inefficient for reconstructing 3D volumes, especially with varying slice counts and orders. Proper sorting by `InstanceNumber` and stacking into a coherent 3D array is crucial but absent.\n",
       "\n",
       "In summary, the current baseline is merely a **technical submission skeleton**, not an actual machine learning model. Our strategy must build the entire model pipeline from scratch, focusing on efficient 3D data handling and state-of-the-art deep learning architectures.\n",
       "\n",
       "#### 2. Specific Model Architecture\n",
       "\n",
       "Given the 3D CT data and the multi-label classification task, a **3D Convolutional Neural Network (CNN)** is the mandatory choice. We need an architecture capable of learning complex spatial features across slices.\n",
       "\n",
       "**Proposed Architecture: 3D ResNeXt-50 (or similar from MONAI Model Zoo)**\n",
       "\n",
       "1.  **Input Preparation:**\n",
       "    *   Read all DICOM slices for a given `SeriesInstanceUID`.\n",
       "    *   Sort slices by `InstanceNumber` and reconstruct the 3D volume.\n",
       "    *   Apply Hounsfield Unit (HU) windowing (e.g., a \"aneurysm/vessel\" specific window like `[-200, 400] HU` or `[0, 600] HU` to highlight vascular structures) and normalize pixel intensities (e.g., to `[0, 1]` or `[-1, 1]`).\n",
       "    *   Resample the volume to a fixed isotropic spacing (e.g., 1mm x 1mm x 1mm) and then resize/pad to a consistent input shape (e.g., 128x128x128 or 256x256x256, depending on GPU memory and target resolution). This is crucial as CT scans often have varying slice thicknesses and in-plane resolutions.\n",
       "\n",
       "2.  **Backbone:** A **3D ResNeXt-50** architecture.\n",
       "    *   **Why ResNeXt?** It combines the benefits of ResNet (residual connections) with grouped convolutions, which improves computational efficiency and accuracy by aggregating transformations from multiple parallel paths. This makes it particularly effective for learning rich features in 3D volumes without excessive computational cost compared to denser architectures.\n",
       "    *   **Implementation:** Leverage robust libraries like **MONAI (Medical Open Network for AI)**, which provides highly optimized 3D CNNs and pre-trained weights for medical imaging. MONAI's `ResNet` or `MedNeXt` models are excellent starting points.\n",
       "\n",
       "3.  **Head:**\n",
       "    *   After the final convolutional block of the 3D ResNeXt backbone, apply **Global Average Pooling** across all spatial dimensions. This reduces the feature map to a fixed-size vector.\n",
       "    *   This vector is then fed into a **fully connected (Dense) layer** with **14 output units**, corresponding to the 14 aneurysm locations/classes.\n",
       "    *   Apply a **Sigmoid activation function** to each output unit, as this is a multi-label classification problem (an image can have multiple aneurysms, or none). Each output will represent the probability of an aneurysm being present at that specific location.\n",
       "\n",
       "This architecture offers a strong balance of representational power and computational efficiency, well-suited for the 3D nature of CT scans and the multi-label classification task.\n",
       "\n",
       "#### 3. Specific Data Augmentation / Feature Engineering Technique\n",
       "\n",
       "**Technique: Advanced 3D Geometric and Intensity Augmentation with Medical Specifics**\n",
       "\n",
       "For medical imaging, standard augmentations are often insufficient. We need techniques that mimic realistic anatomical variations and scanning artifacts.\n",
       "\n",
       "*   **Specific Augmentations:**\n",
       "    1.  **3D Elastic Deformations:** This is *critical* for medical images. It applies a smooth, non-linear deformation field to the image, simulating natural anatomical variations and scanner imperfections. This makes the model robust to slight shifts, rotations, and distortions in patient anatomy. Libraries like MONAI provide efficient implementations.\n",
       "    2.  **Random 3D Rotations and Flips:** Randomly rotate the 3D volume along all three axes (e.g., up to +/- 30 degrees) and perform random flipping along the sagittal, coronal, and axial planes. This helps the model generalize to different patient orientations during scans.\n",
       "    3.  **Random Zoom/Scaling:** Introduce slight variations in zoom to account for differences in patient size or scan acquisition parameters.\n",
       "    4.  **Intensity Augmentations:** Apply random brightness, contrast, and gamma adjustments. Also, add Gaussian noise or introduce simulated \"motion artifacts\" (e.g., by subtly blurring parts of the image along an axis) to mimic real-world scan imperfections.\n",
       "    5.  **MixUp/CutMix (3D):** While more complex for 3D, if feasible, these could also boost generalization by creating synthetic training samples that blend features from multiple inputs.\n",
       "\n",
       "*   **Why these?** These augmentations are tailored to the challenges of medical image analysis, where slight variations in patient positioning, anatomy, or scanner quality can significantly impact model performance. Elastic deformations are particularly powerful for teaching the model to recognize structures despite local anatomical variations.\n",
       "\n",
       "#### 4. Validation Strategy\n",
       "\n",
       "A robust validation strategy is paramount to ensure our model generalizes well to unseen data and accurately reflects real-world performance. Medical imaging competitions are particularly sensitive to data leakage.\n",
       "\n",
       "**Proposed Strategy: Patient-Level 5-Fold Stratified Cross-Validation**\n",
       "\n",
       "1.  **Patient-Level Split:** This is the most crucial step. A single patient (identified by `StudyInstanceUID` or implicitly by `PatientID` if available and unique across studies) must *never* have their scans split across different folds (i.e., some in training, some in validation). All series belonging to the same patient must reside entirely within either the training or validation set for a given fold. This prevents data leakage where the model \"sees\" a patient in training and then again in validation, leading to overly optimistic performance estimates.\n",
       "\n",
       "2.  **5-Fold Cross-Validation:** Divide the dataset into 5 distinct folds. For each fold, one part serves as the validation set, and the remaining four parts form the training set. This provides a more stable and reliable estimate of the model's performance by reducing the variance associated with a single train-validation split.\n",
       "\n",
       "3.  **Stratification:**\n",
       "    *   **Primary Stratification:** Stratify the folds based on the presence of an aneurysm (`Aneurysm Present` label). This ensures that each fold has a representative proportion of aneurysm-positive and aneurysm-negative cases, which is vital for imbalanced datasets.\n",
       "    *   **Secondary Stratification (Optional but Recommended):** Further stratify by the individual aneurysm location labels to ensure all 13 specific locations are represented across folds, especially for rare locations. This can be achieved by stratifying based on the *sum* of positive labels per patient or by more advanced multi-label stratification techniques.\n",
       "\n",
       "4.  **Metric:** Use the official competition metric: **Weighted Log Loss**. Implement this metric for evaluation during training and validation. Monitoring this specific metric is key to optimizing for the competition goal.\n",
       "\n",
       "5.  **Ensembling (for Final Submission):** Train 5 separate models (one for each fold). For the final submission, predict on the test set with all 5 models and average their probabilities for each class. This ensemble approach typically improves robustness and performance by reducing individual model biases.\n",
       "\n",
       "This validation strategy will provide a reliable estimate of our model's performance on unseen patients, prevent data leakage, and guide our model development effectively towards the competition's objectives."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üêç GENERATED CODE\n",
       "Error: Generation failed with 504 The request timed out. Please try again."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code saved to 'submission.py'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. IMPORTS & SETUP ---\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from duckduckgo_search import DDGS\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# --- 2. AUTHENTICATION & CONFIG ---\n",
    "def setup_system():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        # Gemini Auth\n",
    "        api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        # Kaggle Auth\n",
    "        k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "        k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "        \n",
    "        # Set Env Vars (Safest method)\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "        os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "        \n",
    "        # Initialize API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Auth Error: {e}\")\n",
    "        return None\n",
    "\n",
    "k_api = setup_system()\n",
    "\n",
    "# UPDATED: Use the stable 1.5 Flash model\n",
    "model_name = 'gemini-2.5-flash' \n",
    "\n",
    "# Safety Config (Block None to allow medical/technical discussions)\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "# --- HELPER: SAFE GENERATION ---\n",
    "def safe_generate(model, prompt):\n",
    "    \"\"\"\n",
    "    Wrapper to handle empty responses or API hiccups gracefully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt, safety_settings=safety_config)\n",
    "        \n",
    "        # Check if we actually got text back\n",
    "        if response.text: \n",
    "            return response.text\n",
    "        else:\n",
    "            return \"Error: Model returned empty response.\"\n",
    "            \n",
    "    except ValueError:\n",
    "        # This catches the 'finish_reason is 1' but no text error\n",
    "        # We try to inspect the candidate directly if possible, or just fail gracefully\n",
    "        return \"Error: Model finished but generated no text (Silent Block).\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: Generation failed with {str(e)}\"\n",
    "\n",
    "# --- 3. AGENT DEFINITIONS ---\n",
    "\n",
    "class ProblemScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üïµÔ∏è [Scout] Analyzing competition: {slug}...\")\n",
    "        try:\n",
    "            # RSNA Override\n",
    "            if \"rsna\" in slug and \"aneurysm\" in slug:\n",
    "                return \"Goal: Detect intracranial aneurysms on 3D CT. Metric: Weighted Log Loss. Data: 85GB 3D DICOM.\"\n",
    "            \n",
    "            # API Fetch\n",
    "            comps = k_api.competitions_list(search=slug.split('-')[0])\n",
    "            target = next((c for c in comps if c.ref == slug), None)\n",
    "            if target:\n",
    "                return f\"Goal: {target.description[:500]}... Metric: {target.evaluationMetric}.\"\n",
    "            return \"Could not fetch official details via API.\"\n",
    "        except Exception as e:\n",
    "            return f\"Scout Error: {e}\"\n",
    "\n",
    "class ForumScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üì° [Forum] Scanning discussions for: {slug}...\")\n",
    "        readable_name = slug.replace(\"-\", \" \")\n",
    "        query = f\"{readable_name} kaggle discussion solution tricks\"\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=5))\n",
    "            \n",
    "            if not results: return \"No discussions found.\"\n",
    "            summary = \"\\n\".join([f\"- {r['title']}: {r['body'][:200]}...\" for r in results])\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Forum Search Error: {e}\"\n",
    "\n",
    "class NotebookScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üë®‚Äçüíª [Notebook] Hunting for top code...\")\n",
    "        try:\n",
    "            kernels = []\n",
    "            try: kernels = k_api.kernels_list(competition=slug, sort_by='voteCount', page_size=1)\n",
    "            except: pass\n",
    "            \n",
    "            if not kernels:\n",
    "                print(\"   (Strict filter failed, trying broad search...)\")\n",
    "                kernels = k_api.kernels_list(search=slug.split('-')[0], sort_by='voteCount', page_size=1)\n",
    "            \n",
    "            if not kernels: return \"No public code found.\"\n",
    "            \n",
    "            top_k = kernels[0]\n",
    "            print(f\"   (Found: {top_k.title})\")\n",
    "            \n",
    "            k_api.kernels_pull(top_k.ref, path=\"./downloaded_code\")\n",
    "            \n",
    "            code_content = \"\"\n",
    "            files = glob.glob(\"./downloaded_code/*\")\n",
    "            for f_path in files:\n",
    "                if f_path.endswith(\".py\"):\n",
    "                    with open(f_path,'r') as f: code_content += f.read()\n",
    "                elif f_path.endswith(\".ipynb\"):\n",
    "                    with open(f_path,'r') as f:\n",
    "                        nb = json.load(f)\n",
    "                        for c in nb['cells']: \n",
    "                            if c['cell_type']=='code': code_content += \"\".join(c['source']) + \"\\n\"\n",
    "            \n",
    "            if len(code_content) < 50: return \"Code was empty.\"\n",
    "            return f\"--- CODE FROM {top_k.title} ---\\n{code_content[:25000]}\"\n",
    "        except Exception as e:\n",
    "            return f\"Code Download Error: {e}\"\n",
    "\n",
    "class StrategistAgent:\n",
    "    def run(self, slug, goal, forum_intel, code_intel):\n",
    "        print(f\"üß† [Strategist] Formulating plan...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Act as a Kaggle Grandmaster.\n",
    "        Competition: {slug}\n",
    "        \n",
    "        1. OFFICIAL GOAL: {goal}\n",
    "        2. COMMUNITY INTEL: {forum_intel}\n",
    "        3. EXISTING CODE BASELINE: {code_intel[:2000]}... (truncated)\n",
    "        \n",
    "        Task: Write a 'Winning Strategy' report.\n",
    "        - Critique the baseline.\n",
    "        - Identify the specific model architecture we should build.\n",
    "        - Suggest 1 specific data augmentation or feature engineering technique.\n",
    "        - Define the validation strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "class CodeGeneratorAgent:\n",
    "    def run(self, strategy_report):\n",
    "        print(f\"üèóÔ∏è [Builder] Writing final solution.py...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python Developer.\n",
    "        \n",
    "        Based on this strategy:\n",
    "        {strategy_report}\n",
    "        \n",
    "        Write a COMPLETE, RUNNABLE 'main.py' script.\n",
    "        - Include Dataset class, Model class, and Training Loop.\n",
    "        - Use PyTorch.\n",
    "        - Handle the specific data types mentioned (e.g. Images, CSVs).\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "# --- 4. THE ORCHESTRATOR ---\n",
    "\n",
    "class KaggleCommandSystem:\n",
    "    def __init__(self):\n",
    "        self.scout = ProblemScoutAgent()\n",
    "        self.forum = ForumScoutAgent()\n",
    "        self.notebook = NotebookScoutAgent()\n",
    "        self.strategist = StrategistAgent()\n",
    "        self.builder = CodeGeneratorAgent()\n",
    "        \n",
    "    def execute(self, competition_slug):\n",
    "        print(f\"üöÄ STARTING KAGGLE COMMAND FOR: {competition_slug}\\n\" + \"=\"*50)\n",
    "        \n",
    "        goal_data = self.scout.run(competition_slug)\n",
    "        forum_data = self.forum.run(competition_slug)\n",
    "        code_data = self.notebook.run(competition_slug)\n",
    "        \n",
    "        strategy = self.strategist.run(competition_slug, goal_data, forum_data, code_data)\n",
    "        \n",
    "        # If strategy failed, don't try to build code\n",
    "        if \"Error\" in strategy and len(strategy) < 100:\n",
    "            return {\"strategy_report\": strategy, \"final_code\": \"Skipped due to strategy error.\"}\n",
    "            \n",
    "        final_code = self.builder.run(strategy)\n",
    "        \n",
    "        return {\n",
    "            \"strategy_report\": strategy,\n",
    "            \"final_code\": final_code\n",
    "        }\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "system = KaggleCommandSystem()\n",
    "slug = \"rsna-intracranial-aneurysm-detection\" \n",
    "# You can change 'slug' to 'hull-tactical-speed-dating' or any other active comp to test\n",
    "\n",
    "try:\n",
    "    result = system.execute(slug)\n",
    "    \n",
    "    from IPython.display import Markdown, display\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üìÑ STRATEGY REPORT\\n{result['strategy_report']}\"))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üêç GENERATED CODE\\n{result['final_code']}\"))\n",
    "    \n",
    "    with open(\"submission.py\", \"w\") as f:\n",
    "        f.write(result['final_code'])\n",
    "    print(\"‚úÖ Code saved to 'submission.py'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fatal System Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 645.898456,
   "end_time": "2025-11-25T17:25:42.412666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T17:14:56.514210",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
