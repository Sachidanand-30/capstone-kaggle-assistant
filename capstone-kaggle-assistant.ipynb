{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d68e2c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:04:11.125922Z",
     "iopub.status.busy": "2025-11-26T09:04:11.125619Z",
     "iopub.status.idle": "2025-11-26T09:04:16.838415Z",
     "shell.execute_reply": "2025-11-26T09:04:16.837432Z"
    },
    "papermill": {
     "duration": 5.717857,
     "end_time": "2025-11-26T09:04:16.840054",
     "exception": false,
     "start_time": "2025-11-26T09:04:11.122197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa9ff72f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:04:16.845611Z",
     "iopub.status.busy": "2025-11-26T09:04:16.845297Z",
     "iopub.status.idle": "2025-11-26T09:04:21.768061Z",
     "shell.execute_reply": "2025-11-26T09:04:21.766970Z"
    },
    "papermill": {
     "duration": 4.927262,
     "end_time": "2025-11-26T09:04:21.769583",
     "exception": false,
     "start_time": "2025-11-26T09:04:16.842321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables set.\n",
      "‚úÖ Kaggle API Authenticated.\n",
      "‚úÖ Gemini API Authenticated.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & AUTHENTICATION (CORRECT ORDER) ---\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 1. Retrieve Secrets & Set Env Vars FIRST\n",
    "# (We do this BEFORE importing the kaggle library to prevent the crash)\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    # Get secrets\n",
    "    gemini_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "    k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "\n",
    "    # Set Environment Variables\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "    os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "    print(\"‚úÖ Environment variables set.\")\n",
    "    \n",
    "    # 2. NOW it is safe to import the Kaggle API\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    k_api = KaggleApi()\n",
    "    k_api.authenticate()\n",
    "    print(\"‚úÖ Kaggle API Authenticated.\")\n",
    "\n",
    "    # 3. Authenticate Gemini\n",
    "    genai.configure(api_key=gemini_key)\n",
    "    print(\"‚úÖ Gemini API Authenticated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09a524a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:04:21.775082Z",
     "iopub.status.busy": "2025-11-26T09:04:21.774648Z",
     "iopub.status.idle": "2025-11-26T09:14:55.391076Z",
     "shell.execute_reply": "2025-11-26T09:14:55.390204Z"
    },
    "papermill": {
     "duration": 633.621665,
     "end_time": "2025-11-26T09:14:55.393172",
     "exception": false,
     "start_time": "2025-11-26T09:04:21.771507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING KAGGLE COMMAND FOR: rsna-intracranial-aneurysm-detection\n",
      "==================================================\n",
      "üïµÔ∏è [Scout] Analyzing competition: rsna-intracranial-aneurysm-detection...\n",
      "üì° [Forum] Scanning discussions for: rsna-intracranial-aneurysm-detection...\n",
      "üë®‚Äçüíª [Notebook] Hunting for top code...\n",
      "   (Found: RSNA Aneurysm Detection Demo Submission)\n",
      "üß† [Strategist] Formulating plan...\n",
      "üèóÔ∏è [Builder] Writing final solution.py...\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìÑ STRATEGY REPORT\n",
       "As a Kaggle Grandmaster, let's formulate a winning strategy for the RSNA Intracranial Aneurysm Detection competition. The objective is clear: detect and localize intracranial aneurysms on 3D CT scans, optimizing for Weighted Log Loss within strict inference time limits.\n",
       "\n",
       "---\n",
       "\n",
       "## Winning Strategy: RSNA Intracranial Aneurysm Detection\n",
       "\n",
       "### 1. Critique of the Baseline\n",
       "\n",
       "The provided baseline code (`predict` function) is a *minimal submission template*, not an actual aneurysm detection solution. Its critical shortcomings are:\n",
       "\n",
       "1.  **No Predictive Logic:** It completely lacks any machine learning or image processing for aneurysm detection. It simply reads DICOM files and returns hardcoded, non-informative probabilities (0.5 for 'Aneurysm Present', 0.1 for others). This would score extremely poorly.\n",
       "2.  **Lack of Preprocessing:** While it identifies DICOM tags, it performs no critical preprocessing steps like Hounsfield Unit (HU) windowing, intensity normalization, resampling to a common resolution, or handling varying slice thicknesses ‚Äì all essential for 3D medical image analysis.\n",
       "3.  **Inefficient Data Handling:** It iterates through all files and uses `pydicom`, which is standard, but doesn't hint at optimized 3D volume reconstruction or batched processing, crucial for performance on large datasets.\n",
       "4.  **No Model Integration:** There's no placeholder for loading a trained model, performing inference, or processing the model's raw output into the required 14-label probability format.\n",
       "\n",
       "**Conclusion:** The baseline serves only as a structural guide for submission, providing no competitive advantage whatsoever. Our entire strategy must revolve around replacing its core with a robust, high-performance deep learning pipeline.\n",
       "\n",
       "### 2. Model Architecture: 3D Multi-Scale U-Net with Attention\n",
       "\n",
       "Given the 3D nature of the data, the need to detect small, irregularly shaped objects (aneurysms) in specific anatomical locations, and the computational constraints, a robust 3D segmentation-based approach is optimal.\n",
       "\n",
       "**Proposed Architecture: 3D UNETR (UNETR: Transformers for 3D Medical Image Segmentation)**\n",
       "\n",
       "*   **Rationale:**\n",
       "    *   **3D Capability:** Designed for volumetric data, directly processing the 3D CT scans.\n",
       "    *   **Encoder-Decoder Structure (U-Net style):** Provides excellent spatial context and fine-grained localization.\n",
       "    *   **Vision Transformer (ViT) Encoder:** The core innovation of UNETR is using a ViT as the encoder. This allows for capturing global dependencies and long-range contextual information, which is critical for identifying subtle aneurysms amidst complex vascular structures. ViTs have demonstrated superior performance in various vision tasks, including medical imaging, by overcoming the local receptive field limitations of traditional CNNs.\n",
       "    *   **Multi-scale Feature Fusion:** The decoder directly leverages skip connections from the ViT encoder to fuse high-resolution spatial information with the rich semantic features learned by the transformer, ensuring both accurate localization and fine detail preservation.\n",
       "    *   **Multi-Head Output:** Instead of a single segmentation map, the decoder will output **14 distinct segmentation probability maps** (13 anatomical locations + 1 general 'Aneurysm Present' map). This allows the model to learn distinct features for each aneurysm type/location.\n",
       "*   **Implementation Details:**\n",
       "    *   **Input Preprocessing:** Standardize HU values (e.g., windowing to a relevant range like -100 to 400 for vascular structures, clipping, and then normalizing to [0,1]). Resample all volumes to a consistent isotropic resolution (e.g., 0.5mm x 0.5mm x 0.5mm) to handle varying slice thickness and pixel spacing.\n",
       "    *   **Patching Strategy:** The ViT encoder will process input volumes as sequences of 3D patches. Overlapping patches or hierarchical patching might be considered for better context.\n",
       "    *   **Loss Function:** A combination of **Dice Loss** (for segmentation, to handle class imbalance at the voxel level) and **Weighted Log Loss** (for the final aggregated probabilities, directly optimizing the competition metric). The 'Aneurysm Present' map can be trained to be an aggregation of all specific location maps.\n",
       "    *   **Aggregation for Final Output:** After obtaining 14 voxel-wise probability maps, we will define **pre-computed anatomical regions of interest (ROIs)** for each of the 13 locations. For each ROI, we'll extract the **maximum probability** from the corresponding segmentation map. The 'Aneurysm Present' probability can be derived from the global 'Aneurysm Present' segmentation map (e.g., max probability across the entire brain) or as the maximum probability across all 13 location-specific probabilities. This allows for precise localization while providing the required global and regional classification probabilities.\n",
       "\n",
       "### 3. Data Augmentation / Feature Engineering: **Advanced Anomaly Synthesis (Feature Engineering)**\n",
       "\n",
       "Instead of standard augmentations like rotation/scaling (which will also be applied), let's focus on a powerful feature engineering technique that directly addresses the core challenge: detecting rare events.\n",
       "\n",
       "**Specific Technique: Synthetic Aneurysm Generation and Insertion**\n",
       "\n",
       "*   **Problem:** Aneurysms are rare, leading to extreme class imbalance. Models often struggle to learn robust features for rare positive samples.\n",
       "*   **Methodology:**\n",
       "    1.  **Extract Real Aneurysm Patches:** From positive training cases, extract 3D patches (e.g., 32x32x32 voxels) centered around detected aneurysms. These patches capture the true morphology and appearance of aneurysms.\n",
       "    2.  **Deformation and Variation:** Apply subtle random transformations (scaling, rotation, non-rigid deformations, intensity variations) to these extracted aneurysm patches to create diverse synthetic variations. This mimics natural biological variability.\n",
       "    3.  **Insert into Negative Cases:** Select regions in aneurysm-free (negative) CT scans that are anatomically plausible for an aneurysm (e.g., near vessel bifurcations, based on a vascular tree segmentation). Carefully \"paste\" or blend the synthetic aneurysm patches into these locations.\n",
       "    4.  **Label Generation:** Generate corresponding ground truth segmentation masks and classification labels for these newly synthesized aneurysms.\n",
       "*   **Benefits:**\n",
       "    *   **Massively Increases Positive Samples:** Artificially inflates the number of aneurysm instances, mitigating extreme class imbalance.\n",
       "    *   **Improves Generalization:** By placing synthetic aneurysms in diverse anatomical contexts and varying their appearance, the model learns to detect them more robustly, reducing overfitting to specific aneurysm presentations in the training data.\n",
       "    *   **Focuses Model Attention:** Forces the model to learn features that distinguish real aneurysms from normal vessel structures, even in challenging, aneurysm-free backgrounds.\n",
       "    *   **Addresses Small Object Detection:** Provides more examples of small, hard-to-detect objects, which is critical for aneurysm detection.\n",
       "\n",
       "### 4. Validation Strategy: Stratified Patient-Level K-Fold Cross-Validation with Custom Weighted Log Loss\n",
       "\n",
       "A robust validation strategy is paramount for ensuring our model generalizes well and accurately reflects competition performance.\n",
       "\n",
       "1.  **Patient-Level K-Fold Split:**\n",
       "    *   **Critical:** Data from the same patient *must* only appear in either the training or validation set, never both. Using `StudyInstanceUID` or `PatientID` to group studies ensures no data leakage.\n",
       "    *   **K-Folds:** Use 5-Fold Cross-Validation (K=5). This provides a good balance between leveraging enough data for training each fold and having a stable estimate of out-of-fold performance.\n",
       "2.  **Stratification:**\n",
       "    *   **Primary Stratification:** Stratify folds based on the **'Aneurysm Present'** label. This ensures each fold has a representative distribution of positive and negative cases.\n",
       "    *   **Secondary Stratification (Optional but Recommended):** Further stratify by the *number* of aneurysms per patient or the presence of aneurysms in specific, challenging locations (e.g., 'Basilar Tip'), especially if these locations are particularly rare or have higher weights in the metric. This helps ensure all challenging scenarios are present in each fold's validation set.\n",
       "3.  **Metric Matching:**\n",
       "    *   **Custom Weighted Log Loss:** Implement the exact competition metric (Weighted Log Loss, including the specific weights for 'Aneurysm Present' and individual locations) as our primary validation metric. This ensures we are optimizing directly for the competition's objective.\n",
       "    *   **Monitoring:** Track both the overall Weighted Log Loss and individual Log Loss for 'Aneurysm Present' and specific locations during training to identify areas of weakness.\n",
       "4.  **Ensembling and Confidence Calibration:**\n",
       "    *   **Model Averaging:** Train an independent model for each of the K folds. For final submission, average the predictions from all K models (test-time augmentation could also be used). This significantly reduces variance and improves robustness.\n",
       "    *   **Temperature Scaling / Platt Scaling:** After training, apply a post-processing calibration technique (e.g., temperature scaling on a held-out calibration set or validation set) to fine-tune the output probabilities. Weighted Log Loss is sensitive to well-calibrated probabilities.\n",
       "5.  **Inference Time Simulation:**\n",
       "    *   **Local Test Set:** Create a small, representative local test set to simulate the inference environment. Regularly test model inference speed and memory footprint on this set to ensure compliance with the 30-minute per series limit. This is crucial given the 3D data and potential for large models.\n",
       "\n",
       "This comprehensive strategy, from advanced architecture and data engineering to rigorous validation, aims to build a robust and high-performing solution for aneurysm detection."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üêç GENERATED CODE\n",
       "Error: Generation failed with Timeout of 600.0s exceeded, last exception: 503 upstream request timeout"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code saved to 'submission.py'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. IMPORTS & SETUP ---\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from ddgs import DDGS\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# --- 2. AUTHENTICATION & CONFIG ---\n",
    "def setup_system():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        # Gemini Auth\n",
    "        api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        # Kaggle Auth\n",
    "        k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "        k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "        \n",
    "        # Set Env Vars (Safest method)\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "        os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "        \n",
    "        # Initialize API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Auth Error: {e}\")\n",
    "        return None\n",
    "\n",
    "k_api = setup_system()\n",
    "\n",
    "# UPDATED: Use the stable 1.5 Flash model\n",
    "model_name = 'gemini-2.5-flash' \n",
    "\n",
    "# Safety Config (Block None to allow medical/technical discussions)\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "# --- HELPER: SAFE GENERATION ---\n",
    "# --- HELPER: ROBUST GENERATION WITH EXTENDED TIMEOUT ---\n",
    "def safe_generate(model, prompt):\n",
    "    \"\"\"\n",
    "    Uses standard generation but with a 10-minute timeout to allow \n",
    "    for long code blocks without triggering 504 or RST_STREAM errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Request a massive timeout (600s) so it doesn't give up\n",
    "        response = model.generate_content(\n",
    "            prompt, \n",
    "            safety_settings=safety_config,\n",
    "            request_options={'timeout': 3600} \n",
    "        )\n",
    "        \n",
    "        if response.text:\n",
    "            return response.text\n",
    "        else:\n",
    "            return \"Error: Model returned empty response.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: Generation failed with {str(e)}\"\n",
    "\n",
    "# --- 3. AGENT DEFINITIONS ---\n",
    "\n",
    "class ProblemScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üïµÔ∏è [Scout] Analyzing competition: {slug}...\")\n",
    "        try:\n",
    "            # RSNA Override\n",
    "            if \"rsna\" in slug and \"aneurysm\" in slug:\n",
    "                return \"Goal: Detect intracranial aneurysms on 3D CT. Metric: Weighted Log Loss. Data: 85GB 3D DICOM.\"\n",
    "            \n",
    "            # API Fetch\n",
    "            comps = k_api.competitions_list(search=slug.split('-')[0])\n",
    "            target = next((c for c in comps if c.ref == slug), None)\n",
    "            if target:\n",
    "                return f\"Goal: {target.description[:500]}... Metric: {target.evaluationMetric}.\"\n",
    "            return \"Could not fetch official details via API.\"\n",
    "        except Exception as e:\n",
    "            return f\"Scout Error: {e}\"\n",
    "\n",
    "class ForumScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üì° [Forum] Scanning discussions for: {slug}...\")\n",
    "        readable_name = slug.replace(\"-\", \" \")\n",
    "        query = f\"{readable_name} kaggle discussion solution tricks\"\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=5))\n",
    "            \n",
    "            if not results: return \"No discussions found.\"\n",
    "            summary = \"\\n\".join([f\"- {r['title']}: {r['body'][:200]}...\" for r in results])\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Forum Search Error: {e}\"\n",
    "\n",
    "class NotebookScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üë®‚Äçüíª [Notebook] Hunting for top code...\")\n",
    "        try:\n",
    "            kernels = []\n",
    "            try: kernels = k_api.kernels_list(competition=slug, sort_by='voteCount', page_size=1)\n",
    "            except: pass\n",
    "            \n",
    "            if not kernels:\n",
    "                print(\"   (Strict filter failed, trying broad search...)\")\n",
    "                kernels = k_api.kernels_list(search=slug.split('-')[0], sort_by='voteCount', page_size=1)\n",
    "            \n",
    "            if not kernels: return \"No public code found.\"\n",
    "            \n",
    "            top_k = kernels[0]\n",
    "            print(f\"   (Found: {top_k.title})\")\n",
    "            \n",
    "            k_api.kernels_pull(top_k.ref, path=\"./downloaded_code\")\n",
    "            \n",
    "            code_content = \"\"\n",
    "            files = glob.glob(\"./downloaded_code/*\")\n",
    "            for f_path in files:\n",
    "                if f_path.endswith(\".py\"):\n",
    "                    with open(f_path,'r') as f: code_content += f.read()\n",
    "                elif f_path.endswith(\".ipynb\"):\n",
    "                    with open(f_path,'r') as f:\n",
    "                        nb = json.load(f)\n",
    "                        for c in nb['cells']: \n",
    "                            if c['cell_type']=='code': code_content += \"\".join(c['source']) + \"\\n\"\n",
    "            \n",
    "            if len(code_content) < 50: return \"Code was empty.\"\n",
    "            return f\"--- CODE FROM {top_k.title} ---\\n{code_content[:25000]}\"\n",
    "        except Exception as e:\n",
    "            return f\"Code Download Error: {e}\"\n",
    "\n",
    "class StrategistAgent:\n",
    "    def run(self, slug, goal, forum_intel, code_intel):\n",
    "        print(f\"üß† [Strategist] Formulating plan...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Act as a Kaggle Grandmaster.\n",
    "        Competition: {slug}\n",
    "        \n",
    "        1. OFFICIAL GOAL: {goal}\n",
    "        2. COMMUNITY INTEL: {forum_intel}\n",
    "        3. EXISTING CODE BASELINE: {code_intel[:2000]}... (truncated)\n",
    "        \n",
    "        Task: Write a 'Winning Strategy' report.\n",
    "        - Critique the baseline.\n",
    "        - Identify the specific model architecture we should build.\n",
    "        - Suggest 1 specific data augmentation or feature engineering technique.\n",
    "        - Define the validation strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "class CodeGeneratorAgent:\n",
    "    def run(self, strategy_report):\n",
    "        print(f\"üèóÔ∏è [Builder] Writing final solution.py...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python Developer.\n",
    "        \n",
    "        Based on this strategy:\n",
    "        {strategy_report}\n",
    "        \n",
    "        Write a COMPLETE, RUNNABLE 'main.py' script.\n",
    "        - Include Dataset class, Model class, and Training Loop.\n",
    "        - Use PyTorch.\n",
    "        - Handle the specific data types mentioned (e.g. Images, CSVs).\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "# --- 4. THE ORCHESTRATOR ---\n",
    "\n",
    "class KaggleCommandSystem:\n",
    "    def __init__(self):\n",
    "        self.scout = ProblemScoutAgent()\n",
    "        self.forum = ForumScoutAgent()\n",
    "        self.notebook = NotebookScoutAgent()\n",
    "        self.strategist = StrategistAgent()\n",
    "        self.builder = CodeGeneratorAgent()\n",
    "        \n",
    "    def execute(self, competition_slug):\n",
    "        print(f\"üöÄ STARTING KAGGLE COMMAND FOR: {competition_slug}\\n\" + \"=\"*50)\n",
    "        \n",
    "        goal_data = self.scout.run(competition_slug)\n",
    "        forum_data = self.forum.run(competition_slug)\n",
    "        code_data = self.notebook.run(competition_slug)\n",
    "        \n",
    "        strategy = self.strategist.run(competition_slug, goal_data, forum_data, code_data)\n",
    "        \n",
    "        # If strategy failed, don't try to build code\n",
    "        if \"Error\" in strategy and len(strategy) < 100:\n",
    "            return {\"strategy_report\": strategy, \"final_code\": \"Skipped due to strategy error.\"}\n",
    "            \n",
    "        final_code = self.builder.run(strategy)\n",
    "        \n",
    "        return {\n",
    "            \"strategy_report\": strategy,\n",
    "            \"final_code\": final_code\n",
    "        }\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "system = KaggleCommandSystem()\n",
    "slug = \"rsna-intracranial-aneurysm-detection\" \n",
    "# You can change 'slug' to 'hull-tactical-speed-dating' or any other active comp to test\n",
    "\n",
    "try:\n",
    "    result = system.execute(slug)\n",
    "    \n",
    "    from IPython.display import Markdown, display\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üìÑ STRATEGY REPORT\\n{result['strategy_report']}\"))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üêç GENERATED CODE\\n{result['final_code']}\"))\n",
    "    \n",
    "    with open(\"submission.py\", \"w\") as f:\n",
    "        f.write(result['final_code'])\n",
    "    print(\"‚úÖ Code saved to 'submission.py'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fatal System Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 651.361718,
   "end_time": "2025-11-26T09:14:58.178162",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T09:04:06.816444",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
