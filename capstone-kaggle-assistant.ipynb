{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ed8a861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:19:57.594692Z",
     "iopub.status.busy": "2025-11-26T09:19:57.594358Z",
     "iopub.status.idle": "2025-11-26T09:20:03.828853Z",
     "shell.execute_reply": "2025-11-26T09:20:03.827532Z"
    },
    "papermill": {
     "duration": 6.24007,
     "end_time": "2025-11-26T09:20:03.830951",
     "exception": false,
     "start_time": "2025-11-26T09:19:57.590881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6298b5a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:20:03.836548Z",
     "iopub.status.busy": "2025-11-26T09:20:03.836221Z",
     "iopub.status.idle": "2025-11-26T09:20:08.864825Z",
     "shell.execute_reply": "2025-11-26T09:20:08.863759Z"
    },
    "papermill": {
     "duration": 5.033134,
     "end_time": "2025-11-26T09:20:08.866275",
     "exception": false,
     "start_time": "2025-11-26T09:20:03.833141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables set.\n",
      "‚úÖ Kaggle API Authenticated.\n",
      "‚úÖ Gemini API Authenticated.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & AUTHENTICATION (CORRECT ORDER) ---\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 1. Retrieve Secrets & Set Env Vars FIRST\n",
    "# (We do this BEFORE importing the kaggle library to prevent the crash)\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    # Get secrets\n",
    "    gemini_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "    k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "\n",
    "    # Set Environment Variables\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "    os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "    print(\"‚úÖ Environment variables set.\")\n",
    "    \n",
    "    # 2. NOW it is safe to import the Kaggle API\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    k_api = KaggleApi()\n",
    "    k_api.authenticate()\n",
    "    print(\"‚úÖ Kaggle API Authenticated.\")\n",
    "\n",
    "    # 3. Authenticate Gemini\n",
    "    genai.configure(api_key=gemini_key)\n",
    "    print(\"‚úÖ Gemini API Authenticated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e986c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T09:20:08.872291Z",
     "iopub.status.busy": "2025-11-26T09:20:08.871730Z",
     "iopub.status.idle": "2025-11-26T09:31:27.813464Z",
     "shell.execute_reply": "2025-11-26T09:31:27.812402Z"
    },
    "papermill": {
     "duration": 678.948235,
     "end_time": "2025-11-26T09:31:27.816439",
     "exception": false,
     "start_time": "2025-11-26T09:20:08.868204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING KAGGLE COMMAND FOR: rsna-intracranial-aneurysm-detection\n",
      "==================================================\n",
      "üïµÔ∏è [Scout] Analyzing competition: rsna-intracranial-aneurysm-detection...\n",
      "üì° [Forum] Scanning discussions for: rsna-intracranial-aneurysm-detection...\n",
      "üë®‚Äçüíª [Notebook] Hunting for top code...\n",
      "   (Found: RSNA Aneurysm Detection Demo Submission)\n",
      "üß† [Strategist] Formulating plan...\n",
      "üèóÔ∏è [Builder] Writing final solution.py...\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìÑ STRATEGY REPORT\n",
       "As a Kaggle Grandmaster, my approach to the RSNA Intracranial Aneurysm Detection competition focuses on leveraging state-of-the-art 3D deep learning techniques, robust data handling, and rigorous validation to achieve a top-tier solution.\n",
       "\n",
       "---\n",
       "\n",
       "### Winning Strategy Report: RSNA Intracranial Aneurysm Detection\n",
       "\n",
       "#### 1. Critique of the Baseline\n",
       "\n",
       "The provided baseline code serves primarily as a structural template for submission, rather than an intelligent solution for aneurysm detection.\n",
       "\n",
       "*   **Lack of Intelligence:** The baseline contains no machine learning logic. It merely outlines how to read DICOM files, identify series, and format an output DataFrame. This means we are starting from a blank slate regarding model development.\n",
       "*   **Basic DICOM Handling:** While `pydicom` is used, the example code does not demonstrate crucial medical image processing steps such as converting raw DICOM slices into a coherent 3D volume, handling varying `PixelSpacing` or `SliceThickness`, or applying `RescaleIntercept`/`RescaleSlope` for Hounsfield Unit (HU) conversion. These steps are fundamental for consistent model input.\n",
       "*   **No Performance Guidance:** Since there's no actual model, the baseline provides no insights into expected performance or computational complexity. The 30-minute inference limit per series, while generous, could mislead new competitors into thinking a simple model is sufficient, whereas complex 3D processing and advanced models will be necessary.\n",
       "*   **Focus on Boilerplate:** The baseline correctly identifies the `LABEL_COLS`, `ID_COL`, and `DICOM_TAG_ALLOWLIST`, which are important for adherence to the submission format but do not contribute to the core challenge of aneurysm detection.\n",
       "\n",
       "In summary, the baseline is a bare-bones submission scaffolding. Our \"Winning Strategy\" must completely supersede this placeholder with a comprehensive, medically-informed, and computationally efficient deep learning pipeline.\n",
       "\n",
       "#### 2. Specific Model Architecture: Two-Stage 3D Swin-UNETR Ensemble\n",
       "\n",
       "Given the 3D nature of CT data and the need for both detection and classification across multiple anatomical locations, a sophisticated 3D deep learning architecture is essential. We will adopt a multi-stage approach for robustness and performance:\n",
       "\n",
       "**Model Architecture:**\n",
       "We will employ a **3D Swin-UNETR** (Vision Transformer based UNet) as the core architecture, leveraging the robust MONAI framework. Swin-UNETR has demonstrated superior performance in 3D medical image segmentation and localization tasks due to its ability to capture both local and global dependencies within the volumetric data.\n",
       "\n",
       "**Two-Stage Approach:**\n",
       "1.  **Stage 1: Aneurysm Localization/Segmentation Head:**\n",
       "    *   The primary task of the Swin-UNETR will be to output a multi-channel segmentation map. One channel will represent the general probability of *any* aneurysm presence (binary segmentation). Other channels could optionally be trained to segment specific aneurysm locations if high-resolution ground truth masks are available.\n",
       "    *   The encoder-decoder structure of Swin-UNETR is highly effective for this, allowing the model to learn fine-grained spatial features (decoder) while benefiting from contextual global features (encoder).\n",
       "\n",
       "2.  **Stage 2: Location-Specific Classification Head(s):**\n",
       "    *   The output features from the Swin-UNETR's encoder path (or the bottleneck layer) will be fed into a classification head (or multiple parallel heads). This head will learn to classify the 13 specific aneurysm locations and the overall `Aneurysm Present` label based on the contextual information learned by the 3D backbone.\n",
       "    *   Alternatively, we can extract ROIs (Regions of Interest) around the high-probability aneurysm regions detected in Stage 1 and feed these crops into smaller, specialized 3D CNNs for fine-grained classification of the specific locations.\n",
       "    *   The final output will be 14 probabilities (13 specific locations + 1 overall `Aneurysm Present`), directly mapping to the `LABEL_COLS`.\n",
       "\n",
       "**Rationale:**\n",
       "*   **3D Context:** Swin-UNETR inherently processes the full 3D volume, capturing spatial relationships crucial for aneurysm detection.\n",
       "*   **Localization-Aware Classification:** By first localizing potential aneurysms, the model is guided to focus on relevant regions, improving the accuracy of the downstream classification heads.\n",
       "*   **State-of-the-Art:** Vision Transformer architectures are current best-in-class for many medical imaging tasks.\n",
       "*   **Ensembling:** To further boost robustness and performance, we will train an ensemble of these Swin-UNETR models using different data splits and/or slight architectural variations, averaging their predictions for the final submission.\n",
       "\n",
       "#### 3. Specific Data Augmentation & Feature Engineering: Multi-Channel CT Windowing with Elastic Deformations\n",
       "\n",
       "For 3D medical images, robust pre-processing and augmentation are as critical as the model architecture.\n",
       "\n",
       "1.  **Feature Engineering: Multi-Channel CT Windowing & Intensity Normalization:**\n",
       "    *   Instead of feeding raw Hounsfield Units (HU) or a single windowed image, we will generate **multiple input channels** from each 3D CT volume. Each channel will be windowed to highlight different anatomical structures relevant to aneurysm detection.\n",
       "        *   **Vessel Window:** Focus on blood vessels (e.g., window range 100-300 HU) to emphasize the arterial tree.\n",
       "        *   **Brain Parenchyma Window:** A broader window for brain tissue (e.g., window range 0-80 HU) to provide context for surrounding anatomy.\n",
       "        *   **Bone Window (Optional but useful):** A very wide window (e.g., 500-1500 HU) can help identify bone structures, crucial for anatomical orientation and potential artifact detection.\n",
       "    *   Each channel will then be independently normalized to a standard range (e.g., [0, 1] or [-1, 1]). This explicitly provides the model with different \"views\" of the same data, acting as a powerful feature engineering step.\n",
       "\n",
       "2.  **Data Augmentation: 3D Elastic Deformations:**\n",
       "    *   Beyond standard geometric augmentations (random rotations, scaling, flips), **elastic deformations** are crucial for medical images. These non-linear transformations simulate realistic anatomical variations and scanning artifacts, significantly improving the model's robustness and generalization.\n",
       "    *   We will apply 3D elastic deformations using a randomly generated displacement field, which subtly \"stretches\" and \"compresses\" parts of the image volume. This forces the model to learn features that are invariant to minor anatomical shifts, making it more resilient to inter-patient variability.\n",
       "\n",
       "**Rationale:**\n",
       "*   **Multi-Channel Windowing:** Empowers the model with expert-level \"feature selection\" by presenting critical information (vessels, brain, bone) explicitly, rather than relying on the network to learn optimal windowing implicitly.\n",
       "*   **Elastic Deformations:** Directly addresses the challenge of anatomical variability and improves the model's ability to detect aneurysms despite subtle differences in patient anatomy and image acquisition.\n",
       "\n",
       "#### 4. Validation Strategy: Patient-Level Stratified K-Fold Cross-Validation\n",
       "\n",
       "A robust validation strategy is paramount to ensure the model generalizes well to unseen data and avoids patient-level data leakage, which is a common pitfall in medical competitions.\n",
       "\n",
       "1.  **Patient-Level Split:** The most critical aspect is to ensure that all series and studies belonging to a **single patient (`PatientID`) are entirely contained within either the training set or the validation set for any given fold.** This prevents the model from \"seeing\" any data from a patient during training and then evaluating on another scan from the *same* patient, which would lead to an overly optimistic performance estimate.\n",
       "\n",
       "2.  **Stratified K-Fold Cross-Validation:**\n",
       "    *   We will employ **5-Fold Cross-Validation (K=5)**. This provides a good balance between training data size per fold and robust performance estimation across multiple splits.\n",
       "    *   **Stratification:** The folds will be stratified primarily based on the presence of `Aneurysm Present`. Additionally, we will endeavor to balance the distribution of positive cases for the 13 specific aneurysm locations across the folds. This is crucial for handling the class imbalance often seen in medical imaging datasets (where rare conditions are challenging to predict). We might use a multi-label stratification technique or an iterative approach to ensure label balance.\n",
       "\n",
       "3.  **Performance Metrics:**\n",
       "    *   **Primary Metric:** The official **Weighted Log Loss** will be continuously monitored during training and reported for each validation fold. This directly reflects the competition's evaluation.\n",
       "    *   **Secondary Metrics:** We will also monitor **individual Log Loss per label** and **AUC-ROC per label** to gain granular insights into model performance, especially for rare aneurysm locations. Precision, Recall, and F1-score will be useful for understanding classification thresholds.\n",
       "\n",
       "4.  **Early Stopping:** Implement early stopping based on the average Weighted Log Loss across validation folds (or the current fold's validation loss), with a carefully tuned patience parameter to prevent overfitting without premature termination.\n",
       "\n",
       "5.  **Final Model:** The final submission will be an **ensemble of the 5 models** (one trained for each fold). By averaging the predictions of these models, we leverage their collective strengths, reduce variance, and typically achieve a significant boost in performance and robustness compared to a single model.\n",
       "\n",
       "This validation strategy, combined with the proposed architecture and data handling, forms a solid foundation for a top-performing solution in the RSNA Intracranial Aneurysm Detection competition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üêç GENERATED CODE\n",
       "Error: Generation failed with Timeout of 600.0s exceeded, last exception: 503 upstream request timeout"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code saved to 'submission.py'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. IMPORTS & SETUP ---\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from ddgs import DDGS\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# --- 2. AUTHENTICATION & CONFIG ---\n",
    "def setup_system():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        # Gemini Auth\n",
    "        api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        # Kaggle Auth\n",
    "        k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "        k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "        \n",
    "        # Set Env Vars (Safest method)\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "        os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "        \n",
    "        # Initialize API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Auth Error: {e}\")\n",
    "        return None\n",
    "\n",
    "k_api = setup_system()\n",
    "\n",
    "# UPDATED: Use the stable 1.5 Flash model\n",
    "model_name = 'gemini-2.5-flash' \n",
    "\n",
    "# Safety Config (Block None to allow medical/technical discussions)\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "# --- HELPER: SAFE GENERATION ---\n",
    "# --- HELPER: ROBUST GENERATION WITH EXTENDED TIMEOUT ---\n",
    "def safe_generate(model, prompt):\n",
    "    \"\"\"\n",
    "    Uses standard generation but with a 10-minute timeout to allow \n",
    "    for long code blocks without triggering 504 or RST_STREAM errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Request a massive timeout (3600s) so it doesn't give up\n",
    "        response = model.generate_content(\n",
    "            prompt, \n",
    "            safety_settings=safety_config,\n",
    "            request_options={'timeout': 3600} \n",
    "        )\n",
    "        \n",
    "        if response.text:\n",
    "            return response.text\n",
    "        else:\n",
    "            return \"Error: Model returned empty response.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: Generation failed with {str(e)}\"\n",
    "\n",
    "# --- 3. AGENT DEFINITIONS ---\n",
    "\n",
    "class ProblemScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üïµÔ∏è [Scout] Analyzing competition: {slug}...\")\n",
    "        try:\n",
    "            # RSNA Override\n",
    "            if \"rsna\" in slug and \"aneurysm\" in slug:\n",
    "                return \"Goal: Detect intracranial aneurysms on 3D CT. Metric: Weighted Log Loss. Data: 85GB 3D DICOM.\"\n",
    "            \n",
    "            # API Fetch\n",
    "            comps = k_api.competitions_list(search=slug.split('-')[0])\n",
    "            target = next((c for c in comps if c.ref == slug), None)\n",
    "            if target:\n",
    "                return f\"Goal: {target.description[:500]}... Metric: {target.evaluationMetric}.\"\n",
    "            return \"Could not fetch official details via API.\"\n",
    "        except Exception as e:\n",
    "            return f\"Scout Error: {e}\"\n",
    "\n",
    "class ForumScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üì° [Forum] Scanning discussions for: {slug}...\")\n",
    "        readable_name = slug.replace(\"-\", \" \")\n",
    "        query = f\"{readable_name} kaggle discussion solution tricks\"\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=5))\n",
    "            \n",
    "            if not results: return \"No discussions found.\"\n",
    "            summary = \"\\n\".join([f\"- {r['title']}: {r['body'][:200]}...\" for r in results])\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Forum Search Error: {e}\"\n",
    "\n",
    "class NotebookScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üë®‚Äçüíª [Notebook] Hunting for top code...\")\n",
    "        try:\n",
    "            kernels = []\n",
    "            try: kernels = k_api.kernels_list(competition=slug, sort_by='voteCount', page_size=1)\n",
    "            except: pass\n",
    "            \n",
    "            if not kernels:\n",
    "                print(\"   (Strict filter failed, trying broad search...)\")\n",
    "                kernels = k_api.kernels_list(search=slug.split('-')[0], sort_by='voteCount', page_size=1)\n",
    "            \n",
    "            if not kernels: return \"No public code found.\"\n",
    "            \n",
    "            top_k = kernels[0]\n",
    "            print(f\"   (Found: {top_k.title})\")\n",
    "            \n",
    "            k_api.kernels_pull(top_k.ref, path=\"./downloaded_code\")\n",
    "            \n",
    "            code_content = \"\"\n",
    "            files = glob.glob(\"./downloaded_code/*\")\n",
    "            for f_path in files:\n",
    "                if f_path.endswith(\".py\"):\n",
    "                    with open(f_path,'r') as f: code_content += f.read()\n",
    "                elif f_path.endswith(\".ipynb\"):\n",
    "                    with open(f_path,'r') as f:\n",
    "                        nb = json.load(f)\n",
    "                        for c in nb['cells']: \n",
    "                            if c['cell_type']=='code': code_content += \"\".join(c['source']) + \"\\n\"\n",
    "            \n",
    "            if len(code_content) < 50: return \"Code was empty.\"\n",
    "            return f\"--- CODE FROM {top_k.title} ---\\n{code_content[:25000]}\"\n",
    "        except Exception as e:\n",
    "            return f\"Code Download Error: {e}\"\n",
    "\n",
    "class StrategistAgent:\n",
    "    def run(self, slug, goal, forum_intel, code_intel):\n",
    "        print(f\"üß† [Strategist] Formulating plan...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Act as a Kaggle Grandmaster.\n",
    "        Competition: {slug}\n",
    "        \n",
    "        1. OFFICIAL GOAL: {goal}\n",
    "        2. COMMUNITY INTEL: {forum_intel}\n",
    "        3. EXISTING CODE BASELINE: {code_intel[:2000]}... (truncated)\n",
    "        \n",
    "        Task: Write a 'Winning Strategy' report.\n",
    "        - Critique the baseline.\n",
    "        - Identify the specific model architecture we should build.\n",
    "        - Suggest 1 specific data augmentation or feature engineering technique.\n",
    "        - Define the validation strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "class CodeGeneratorAgent:\n",
    "    def run(self, strategy_report):\n",
    "        print(f\"üèóÔ∏è [Builder] Writing final solution.py...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python Developer.\n",
    "        \n",
    "        Based on this strategy:\n",
    "        {strategy_report}\n",
    "        \n",
    "        Write a COMPLETE, RUNNABLE 'main.py' script.\n",
    "        - Include Dataset class, Model class, and Training Loop.\n",
    "        - Use PyTorch.\n",
    "        - Handle the specific data types mentioned (e.g. Images, CSVs).\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "# --- 4. THE ORCHESTRATOR ---\n",
    "\n",
    "class KaggleCommandSystem:\n",
    "    def __init__(self):\n",
    "        self.scout = ProblemScoutAgent()\n",
    "        self.forum = ForumScoutAgent()\n",
    "        self.notebook = NotebookScoutAgent()\n",
    "        self.strategist = StrategistAgent()\n",
    "        self.builder = CodeGeneratorAgent()\n",
    "        \n",
    "    def execute(self, competition_slug):\n",
    "        print(f\"üöÄ STARTING KAGGLE COMMAND FOR: {competition_slug}\\n\" + \"=\"*50)\n",
    "        \n",
    "        goal_data = self.scout.run(competition_slug)\n",
    "        forum_data = self.forum.run(competition_slug)\n",
    "        code_data = self.notebook.run(competition_slug)\n",
    "        \n",
    "        strategy = self.strategist.run(competition_slug, goal_data, forum_data, code_data)\n",
    "        \n",
    "        # If strategy failed, don't try to build code\n",
    "        if \"Error\" in strategy and len(strategy) < 100:\n",
    "            return {\"strategy_report\": strategy, \"final_code\": \"Skipped due to strategy error.\"}\n",
    "            \n",
    "        final_code = self.builder.run(strategy)\n",
    "        \n",
    "        return {\n",
    "            \"strategy_report\": strategy,\n",
    "            \"final_code\": final_code\n",
    "        }\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "system = KaggleCommandSystem()\n",
    "slug = \"rsna-intracranial-aneurysm-detection\" \n",
    "# You can change 'slug' to 'hull-tactical-speed-dating' or any other active comp to test\n",
    "\n",
    "try:\n",
    "    result = system.execute(slug)\n",
    "    \n",
    "    from IPython.display import Markdown, display\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üìÑ STRATEGY REPORT\\n{result['strategy_report']}\"))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üêç GENERATED CODE\\n{result['final_code']}\"))\n",
    "    \n",
    "    with open(\"submission.py\", \"w\") as f:\n",
    "        f.write(result['final_code'])\n",
    "    print(\"‚úÖ Code saved to 'submission.py'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fatal System Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 698.494604,
   "end_time": "2025-11-26T09:31:31.293129",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T09:19:52.798525",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
