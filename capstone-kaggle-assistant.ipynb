{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4e4304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:52:00.859748Z",
     "iopub.status.busy": "2025-11-26T08:52:00.859368Z",
     "iopub.status.idle": "2025-11-26T08:52:06.803122Z",
     "shell.execute_reply": "2025-11-26T08:52:06.801693Z"
    },
    "papermill": {
     "duration": 5.949788,
     "end_time": "2025-11-26T08:52:06.805315",
     "exception": false,
     "start_time": "2025-11-26T08:52:00.855527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install ddgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3970af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:52:06.812304Z",
     "iopub.status.busy": "2025-11-26T08:52:06.811891Z",
     "iopub.status.idle": "2025-11-26T08:52:11.812586Z",
     "shell.execute_reply": "2025-11-26T08:52:11.811218Z"
    },
    "papermill": {
     "duration": 5.006473,
     "end_time": "2025-11-26T08:52:11.814569",
     "exception": false,
     "start_time": "2025-11-26T08:52:06.808096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables set.\n",
      "‚úÖ Kaggle API Authenticated.\n",
      "‚úÖ Gemini API Authenticated.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: SETUP & AUTHENTICATION (CORRECT ORDER) ---\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# 1. Retrieve Secrets & Set Env Vars FIRST\n",
    "# (We do this BEFORE importing the kaggle library to prevent the crash)\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "try:\n",
    "    # Get secrets\n",
    "    gemini_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "    k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "    k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "\n",
    "    # Set Environment Variables\n",
    "    os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "    os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "    print(\"‚úÖ Environment variables set.\")\n",
    "    \n",
    "    # 2. NOW it is safe to import the Kaggle API\n",
    "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "    \n",
    "    k_api = KaggleApi()\n",
    "    k_api.authenticate()\n",
    "    print(\"‚úÖ Kaggle API Authenticated.\")\n",
    "\n",
    "    # 3. Authenticate Gemini\n",
    "    genai.configure(api_key=gemini_key)\n",
    "    print(\"‚úÖ Gemini API Authenticated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b485f059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T08:52:11.821392Z",
     "iopub.status.busy": "2025-11-26T08:52:11.820871Z",
     "iopub.status.idle": "2025-11-26T09:02:38.269386Z",
     "shell.execute_reply": "2025-11-26T09:02:38.267946Z"
    },
    "papermill": {
     "duration": 626.453841,
     "end_time": "2025-11-26T09:02:38.270878",
     "exception": false,
     "start_time": "2025-11-26T08:52:11.817037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING KAGGLE COMMAND FOR: rsna-intracranial-aneurysm-detection\n",
      "==================================================\n",
      "üïµÔ∏è [Scout] Analyzing competition: rsna-intracranial-aneurysm-detection...\n",
      "üì° [Forum] Scanning discussions for: rsna-intracranial-aneurysm-detection...\n",
      "üë®‚Äçüíª [Notebook] Hunting for top code...\n",
      "   (Found: RSNA Aneurysm Detection Demo Submission)\n",
      "üß† [Strategist] Formulating plan...\n",
      "üèóÔ∏è [Builder] Writing final solution.py...\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üìÑ STRATEGY REPORT\n",
       "As a Kaggle Grandmaster, my winning strategy for the RSNA Intracranial Aneurysm Detection competition will focus on leveraging state-of-the-art 3D deep learning, robust data handling, and a meticulous validation approach to navigate the complexities of medical imaging and the strict inference time limits.\n",
       "\n",
       "## Winning Strategy: RSNA Intracranial Aneurysm Detection\n",
       "\n",
       "### 1. Critique of the Existing Code Baseline\n",
       "\n",
       "The provided baseline code serves primarily as an **API placeholder** rather than a functional machine learning solution.\n",
       "\n",
       "**Key Criticisms:**\n",
       "\n",
       "1.  **No Inference Logic:** The `predict` function is entirely devoid of any actual aneurysm detection or classification logic. It only extracts the `series_id` and attempts to list files, then gets truncated. It doesn't load DICOM data into a 3D volume, preprocess it, or run any model inference.\n",
       "2.  **Missing Preprocessing:** The most critical step for 3D DICOM data ‚Äì loading multiple slices, stacking them into a 3D volume, handling diverse `PixelSpacing` and `SliceThickness`, windowing (e.g., brain window, vessel window), and intensity normalization ‚Äì is completely absent.\n",
       "3.  **No Model Integration:** There's no neural network definition, no loading of pre-trained weights, and no forward pass implementation.\n",
       "4.  **Dummy Output:** While not fully shown, the truncated code implies a placeholder for generating predictions for `LABEL_COLS`, which would likely be default values rather than learned probabilities.\n",
       "5.  **Performance Blind:** Without actual inference, the baseline gives no indication of how to meet the crucial 30-minute inference limit per series. This will be a major engineering challenge for a comprehensive 3D model.\n",
       "\n",
       "**In essence, the baseline is a barebones scaffold that defines the competition's input/output interface, but provides zero predictive capability. Our winning strategy must entirely replace its core logic with a sophisticated 3D deep learning pipeline.**\n",
       "\n",
       "### 2. Specific Model Architecture\n",
       "\n",
       "Given the 3D CT angiography data and the need to detect and localize aneurysms across multiple anatomical regions, a **3D Vision Transformer (ViT) based UNet-like architecture** will be employed. This combines the strengths of convolutional locality with the global context understanding of Transformers, crucial for complex anatomical structures.\n",
       "\n",
       "**Proposed Architecture: 3D Swin-UNETR (or similar MONAI-based 3D UNet with a strong ViT encoder)**\n",
       "\n",
       "*   **Encoder:** A 3D Swin Transformer (e.g., `SwinUNETR` from `MONAI` or a custom implementation).\n",
       "    *   **Rationale:** Swin Transformers excel at hierarchical feature representation and efficient self-attention across 3D volumes. This allows the model to capture both fine-grained local details (important for small aneurysms) and global anatomical context (important for localizing aneurysms within larger vascular structures). Self-supervised pre-training (e.g., using masked image modeling or contrastive learning on large datasets like Radiology-Net or even general medical image datasets) will be crucial for initializing this encoder effectively.\n",
       "*   **Decoder:** A lightweight 3D decoder path that upsamples features from the Swin Transformer encoder.\n",
       "    *   **Rationale:** This part will fuse high-level semantic features with low-level spatial features via skip connections (similar to a UNet), enabling precise localization within the 3D volume.\n",
       "*   **Output Heads:**\n",
       "    *   **Segmentation Head (Auxiliary Task):** A voxel-wise segmentation head predicting aneurysm masks. While not directly scored, this forces the model to learn precise localization, which can significantly improve classification performance by providing stronger anatomical priors.\n",
       "    *   **Classification Heads (Main Task):** Multiple global average pooling layers followed by fully connected layers, one for each of the 14 `LABEL_COLS`.\n",
       "        *   **Rationale:** The segmentation head helps learn rich, spatially-aware features. These features are then aggregated (via global pooling) for the final multi-label classification, directly addressing the competition metric. This multi-task learning approach generally leads to more robust models.\n",
       "\n",
       "**Why this choice?**\n",
       "*   **3D Data:** Directly processes volumetric data, avoiding information loss from 2D slicing.\n",
       "*   **Global Context:** ViT encoders handle long-range dependencies, essential for understanding complex cerebrovascular anatomy.\n",
       "*   **Localization (Auxiliary):** Segmentation helps the model focus on anatomical anomalies rather than just abstract features, improving precision.\n",
       "*   **State-of-the-Art:** Represents a strong current trend in medical image analysis for both segmentation and classification tasks.\n",
       "*   **Efficiency:** Swin Transformers are designed for efficiency, critical for large 3D inputs and inference time limits.\n",
       "\n",
       "### 3. Specific Data Augmentation & Feature Engineering Technique\n",
       "\n",
       "**Proposed Technique: Anatomical-Aware 3D Augmentations with Vessel Segmentation as a Soft Prior.**\n",
       "\n",
       "This technique combines two powerful concepts for medical imaging: realistic anatomical variations and leveraging domain knowledge.\n",
       "\n",
       "1.  **Anatomical-Aware 3D Augmentations:**\n",
       "    *   **Elastic Deformations:** Apply non-linear, realistic deformations to the 3D volume. This simulates natural variations in patient anatomy, making the model robust to slight shifts and distortions in vessel structure and brain morphology. (e.g., using `MONAI`'s `Rand3DElasticd`).\n",
       "    *   **Contextual Cropping:** During training, instead of purely random cropping, prioritize sampling 3D patches that contain major cerebral arteries or known aneurysm locations (if segmentation masks or bounding box annotations are available). For cases without aneurysms, ensure a diverse set of vessel-rich and brain tissue regions are sampled.\n",
       "    *   **Intensity Adjustments:** Random brightness/contrast, gamma correction, and realistic CT noise injection. This handles variability in scanner acquisition parameters and dose levels.\n",
       "    *   **Windowing Variation:** Randomly vary the CT window level and width (e.g., between 'brain window', 'vessel window', 'soft tissue window') within reasonable medical ranges during training. This acts as both an augmentation and a form of feature engineering, exposing the model to different tissue contrasts.\n",
       "\n",
       "2.  **Vessel Segmentation as a Soft Prior (Feature Engineering):**\n",
       "    *   **Pre-computed Vessel Mask:** Train a separate, lighter 3D U-Net to segment the cerebral vasculature from the raw CT angiography scans. This can be done offline or during the training pipeline using a pre-trained model.\n",
       "    *   **Input Channel:** The predicted *probability map* (or a binarized mask) of the vessel segmentation is then concatenated as an additional input channel to the main aneurysm detection model (alongside the original CT volume).\n",
       "    *   **Rationale:** Aneurysms are anomalies of blood vessels. Providing the model with an explicit \"vesselness\" map focuses its attention on the most relevant anatomical structures, reducing false positives in non-vascular regions and aiding in the detection of small, subtle aneurysms embedded within complex vascular trees. This acts as a powerful, anatomically-informed feature, guiding the model's learning towards critical areas.\n",
       "\n",
       "### 4. Validation Strategy\n",
       "\n",
       "A robust **Stratified Patient-Level K-Fold Cross-Validation** strategy will be implemented to ensure the model's generalization capability and prevent data leakage.\n",
       "\n",
       "1.  **Patient-Level Split:** The fundamental unit for splitting data will be the `PatientID`. All studies and series belonging to a single `PatientID` must reside entirely within either the training set or the validation set for any given fold. This is crucial to prevent the model from \"seeing\" parts of a patient's anatomy during training and then being evaluated on a different scan from the *same patient*, leading to an overoptimistic assessment of performance.\n",
       "\n",
       "2.  **Stratification:**\n",
       "    *   **Primary Stratification:** Stratify based on the `Aneurysm Present` label. This ensures that each fold maintains a similar proportion of aneurysm-positive and aneurysm-negative patients, which is vital due to the inherent class imbalance of aneurysms.\n",
       "    *   **Secondary Stratification (if feasible):** Further stratification based on the presence of specific aneurysm locations (`LABEL_COLS`) or the total number of aneurysms per patient could be considered if the distribution is highly skewed, though patient-level `Aneurysm Present` is the most critical.\n",
       "\n",
       "3.  **K-Fold Cross-Validation:**\n",
       "    *   Utilize `K=5` or `K=4` folds. Training multiple models (one per fold) allows for a more reliable estimate of performance and can be leveraged for ensemble predictions, which often boost final scores.\n",
       "    *   During each fold, the model is trained on K-1 folds and validated on the remaining 1 fold.\n",
       "\n",
       "4.  **Metric Monitoring:** The official competition metric, **Weighted Log Loss**, will be the primary metric monitored for early stopping and model selection during validation. This direct alignment ensures that models are optimized for the competition's objective.\n",
       "\n",
       "5.  **External Validation (Grandmaster Touch):** If additional, independently sourced public datasets of intracranial CTAs with aneurysm labels are available (e.g., from other research initiatives or previous similar competitions), a final model evaluation on this *completely unseen external dataset* would provide the ultimate testament to the model's true generalization and clinical utility, exceeding what can be learned solely from the competition data splits. This step, while not directly contributing to the Kaggle score, aligns with a Grandmaster's commitment to robust and reliable medical AI.\n",
       "\n",
       "This comprehensive strategy, from cutting-edge architecture and intelligent data handling to rigorous validation, provides a clear path to achieve a top-tier solution in the RSNA Intracranial Aneurysm Detection competition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## üêç GENERATED CODE\n",
       "Error: Generation failed with 504 The request timed out. Please try again."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Code saved to 'submission.py'\n"
     ]
    }
   ],
   "source": [
    "# --- 1. IMPORTS & SETUP ---\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from ddgs import DDGS\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# --- 2. AUTHENTICATION & CONFIG ---\n",
    "def setup_system():\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        # Gemini Auth\n",
    "        api_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        # Kaggle Auth\n",
    "        k_user = user_secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "        k_key = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "        \n",
    "        # Set Env Vars (Safest method)\n",
    "        os.environ[\"KAGGLE_USERNAME\"] = k_user\n",
    "        os.environ[\"KAGGLE_KEY\"] = k_key\n",
    "        \n",
    "        # Initialize API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Auth Error: {e}\")\n",
    "        return None\n",
    "\n",
    "k_api = setup_system()\n",
    "\n",
    "# UPDATED: Use the stable 1.5 Flash model\n",
    "model_name = 'gemini-2.5-flash' \n",
    "\n",
    "# Safety Config (Block None to allow medical/technical discussions)\n",
    "safety_config = {\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "# --- HELPER: SAFE GENERATION ---\n",
    "# --- HELPER: ROBUST GENERATION WITH EXTENDED TIMEOUT ---\n",
    "def safe_generate(model, prompt):\n",
    "    \"\"\"\n",
    "    Uses standard generation but with a 10-minute timeout to allow \n",
    "    for long code blocks without triggering 504 or RST_STREAM errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Request a massive timeout (600s) so it doesn't give up\n",
    "        response = model.generate_content(\n",
    "            prompt, \n",
    "            safety_settings=safety_config,\n",
    "            request_options={'timeout': 600} \n",
    "        )\n",
    "        \n",
    "        if response.text:\n",
    "            return response.text\n",
    "        else:\n",
    "            return \"Error: Model returned empty response.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: Generation failed with {str(e)}\"\n",
    "\n",
    "# --- 3. AGENT DEFINITIONS ---\n",
    "\n",
    "class ProblemScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üïµÔ∏è [Scout] Analyzing competition: {slug}...\")\n",
    "        try:\n",
    "            # RSNA Override\n",
    "            if \"rsna\" in slug and \"aneurysm\" in slug:\n",
    "                return \"Goal: Detect intracranial aneurysms on 3D CT. Metric: Weighted Log Loss. Data: 85GB 3D DICOM.\"\n",
    "            \n",
    "            # API Fetch\n",
    "            comps = k_api.competitions_list(search=slug.split('-')[0])\n",
    "            target = next((c for c in comps if c.ref == slug), None)\n",
    "            if target:\n",
    "                return f\"Goal: {target.description[:500]}... Metric: {target.evaluationMetric}.\"\n",
    "            return \"Could not fetch official details via API.\"\n",
    "        except Exception as e:\n",
    "            return f\"Scout Error: {e}\"\n",
    "\n",
    "class ForumScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üì° [Forum] Scanning discussions for: {slug}...\")\n",
    "        readable_name = slug.replace(\"-\", \" \")\n",
    "        query = f\"{readable_name} kaggle discussion solution tricks\"\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = list(ddgs.text(query, max_results=5))\n",
    "            \n",
    "            if not results: return \"No discussions found.\"\n",
    "            summary = \"\\n\".join([f\"- {r['title']}: {r['body'][:200]}...\" for r in results])\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            return f\"Forum Search Error: {e}\"\n",
    "\n",
    "class NotebookScoutAgent:\n",
    "    def run(self, slug):\n",
    "        print(f\"üë®‚Äçüíª [Notebook] Hunting for top code...\")\n",
    "        try:\n",
    "            kernels = []\n",
    "            try: kernels = k_api.kernels_list(competition=slug, sort_by='voteCount', page_size=1)\n",
    "            except: pass\n",
    "            \n",
    "            if not kernels:\n",
    "                print(\"   (Strict filter failed, trying broad search...)\")\n",
    "                kernels = k_api.kernels_list(search=slug.split('-')[0], sort_by='voteCount', page_size=1)\n",
    "            \n",
    "            if not kernels: return \"No public code found.\"\n",
    "            \n",
    "            top_k = kernels[0]\n",
    "            print(f\"   (Found: {top_k.title})\")\n",
    "            \n",
    "            k_api.kernels_pull(top_k.ref, path=\"./downloaded_code\")\n",
    "            \n",
    "            code_content = \"\"\n",
    "            files = glob.glob(\"./downloaded_code/*\")\n",
    "            for f_path in files:\n",
    "                if f_path.endswith(\".py\"):\n",
    "                    with open(f_path,'r') as f: code_content += f.read()\n",
    "                elif f_path.endswith(\".ipynb\"):\n",
    "                    with open(f_path,'r') as f:\n",
    "                        nb = json.load(f)\n",
    "                        for c in nb['cells']: \n",
    "                            if c['cell_type']=='code': code_content += \"\".join(c['source']) + \"\\n\"\n",
    "            \n",
    "            if len(code_content) < 50: return \"Code was empty.\"\n",
    "            return f\"--- CODE FROM {top_k.title} ---\\n{code_content[:25000]}\"\n",
    "        except Exception as e:\n",
    "            return f\"Code Download Error: {e}\"\n",
    "\n",
    "class StrategistAgent:\n",
    "    def run(self, slug, goal, forum_intel, code_intel):\n",
    "        print(f\"üß† [Strategist] Formulating plan...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Act as a Kaggle Grandmaster.\n",
    "        Competition: {slug}\n",
    "        \n",
    "        1. OFFICIAL GOAL: {goal}\n",
    "        2. COMMUNITY INTEL: {forum_intel}\n",
    "        3. EXISTING CODE BASELINE: {code_intel[:2000]}... (truncated)\n",
    "        \n",
    "        Task: Write a 'Winning Strategy' report.\n",
    "        - Critique the baseline.\n",
    "        - Identify the specific model architecture we should build.\n",
    "        - Suggest 1 specific data augmentation or feature engineering technique.\n",
    "        - Define the validation strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "class CodeGeneratorAgent:\n",
    "    def run(self, strategy_report):\n",
    "        print(f\"üèóÔ∏è [Builder] Writing final solution.py...\")\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert Python Developer.\n",
    "        \n",
    "        Based on this strategy:\n",
    "        {strategy_report}\n",
    "        \n",
    "        Write a COMPLETE, RUNNABLE 'main.py' script.\n",
    "        - Include Dataset class, Model class, and Training Loop.\n",
    "        - Use PyTorch.\n",
    "        - Handle the specific data types mentioned (e.g. Images, CSVs).\n",
    "        \"\"\"\n",
    "        \n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        return safe_generate(model, prompt)\n",
    "\n",
    "# --- 4. THE ORCHESTRATOR ---\n",
    "\n",
    "class KaggleCommandSystem:\n",
    "    def __init__(self):\n",
    "        self.scout = ProblemScoutAgent()\n",
    "        self.forum = ForumScoutAgent()\n",
    "        self.notebook = NotebookScoutAgent()\n",
    "        self.strategist = StrategistAgent()\n",
    "        self.builder = CodeGeneratorAgent()\n",
    "        \n",
    "    def execute(self, competition_slug):\n",
    "        print(f\"üöÄ STARTING KAGGLE COMMAND FOR: {competition_slug}\\n\" + \"=\"*50)\n",
    "        \n",
    "        goal_data = self.scout.run(competition_slug)\n",
    "        forum_data = self.forum.run(competition_slug)\n",
    "        code_data = self.notebook.run(competition_slug)\n",
    "        \n",
    "        strategy = self.strategist.run(competition_slug, goal_data, forum_data, code_data)\n",
    "        \n",
    "        # If strategy failed, don't try to build code\n",
    "        if \"Error\" in strategy and len(strategy) < 100:\n",
    "            return {\"strategy_report\": strategy, \"final_code\": \"Skipped due to strategy error.\"}\n",
    "            \n",
    "        final_code = self.builder.run(strategy)\n",
    "        \n",
    "        return {\n",
    "            \"strategy_report\": strategy,\n",
    "            \"final_code\": final_code\n",
    "        }\n",
    "\n",
    "# --- 5. EXECUTION ---\n",
    "system = KaggleCommandSystem()\n",
    "slug = \"rsna-intracranial-aneurysm-detection\" \n",
    "# You can change 'slug' to 'hull-tactical-speed-dating' or any other active comp to test\n",
    "\n",
    "try:\n",
    "    result = system.execute(slug)\n",
    "    \n",
    "    from IPython.display import Markdown, display\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üìÑ STRATEGY REPORT\\n{result['strategy_report']}\"))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    display(Markdown(f\"## üêç GENERATED CODE\\n{result['final_code']}\"))\n",
    "    \n",
    "    with open(\"submission.py\", \"w\") as f:\n",
    "        f.write(result['final_code'])\n",
    "    print(\"‚úÖ Code saved to 'submission.py'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fatal System Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 645.474827,
   "end_time": "2025-11-26T09:02:41.477095",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-26T08:51:56.002268",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
